{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMr3tJlcX26rU4QsWuIi6d6"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Reading the input data\n",
        "from google.colab import drive\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FhwNRvOaQhU8",
        "outputId": "13fb249c-bd21-49eb-c537-2628338ae961"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Reading input ply data"
      ],
      "metadata": {
        "id": "O0lmgasRB6Mw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install plyfile"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_CF0ap8JC4rd",
        "outputId": "d2e6c78b-90df-484e-e6ab-342f6feb2ea6"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting plyfile\n",
            "  Downloading plyfile-1.0.3-py3-none-any.whl (23 kB)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from plyfile) (1.25.2)\n",
            "Installing collected packages: plyfile\n",
            "Successfully installed plyfile-1.0.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "from torch.utils.data import Dataset\n",
        "from plyfile import PlyData\n",
        "\n",
        "def load_ply(path, with_faces=False, with_color=False):\n",
        "    # print(path)\n",
        "    ply_data = PlyData.read(path)\n",
        "    points = ply_data['vertex']\n",
        "    points = np.vstack([points['x'], points['y'], points['z']]).T\n",
        "    ret_val = [points]\n",
        "\n",
        "    if with_faces:\n",
        "        faces = np.vstack(ply_data['face']['vertex_indices'])\n",
        "        ret_val.append(faces)\n",
        "\n",
        "    if with_color:\n",
        "        r = np.vstack(ply_data['vertex']['red'])\n",
        "        g = np.vstack(ply_data['vertex']['green'])\n",
        "        b = np.vstack(ply_data['vertex']['blue'])\n",
        "        color = np.hstack((r, g, b))\n",
        "        ret_val.append(color)\n",
        "\n",
        "    if len(ret_val) == 1:  # Unwrap the list\n",
        "        ret_val = ret_val[0]\n",
        "\n",
        "    return ret_val\n",
        "\n",
        "def write_ply(points, output_path, faces=None, colors=None):\n",
        "    with open(output_path, 'w') as f:\n",
        "        f.write('ply\\n')\n",
        "        f.write('format ascii 1.0\\n')\n",
        "        f.write('element vertex {}\\n'.format(len(points)))\n",
        "        f.write('property float x\\n')\n",
        "        f.write('property float y\\n')\n",
        "        f.write('property float z\\n')\n",
        "\n",
        "        if colors is not None:\n",
        "            f.write('property uchar red\\n')\n",
        "            f.write('property uchar green\\n')\n",
        "            f.write('property uchar blue\\n')\n",
        "\n",
        "        if faces is not None:\n",
        "            f.write('element face {}\\n'.format(len(faces)))\n",
        "            f.write('property list uchar int vertex_index\\n')\n",
        "            f.write('end_header\\n')\n",
        "\n",
        "            for point in points:\n",
        "                f.write('{} {} {}\\n'.format(point[0], point[1], point[2]))\n",
        "\n",
        "            for face in faces:\n",
        "                f.write('3 {} {} {}\\n'.format(face[0], face[1], face[2]))\n",
        "        else:\n",
        "            f.write('end_header\\n')\n",
        "\n",
        "            for point in points:\n",
        "                f.write('{} {} {}\\n'.format(point[0], point[1], point[2]))\n",
        "\n",
        "\n",
        "    # print(\"PLY file saved to:\", output_path)\n",
        "\n",
        "\n",
        "\n",
        "class PointCloudDataset(Dataset):\n",
        "    def __init__(self, root_dir):\n",
        "        self.root_dir = root_dir\n",
        "        self.file_paths = self._get_file_paths()\n",
        "\n",
        "    def _get_file_paths(self):\n",
        "        file_paths = []\n",
        "        for root, dirs, files in os.walk(self.root_dir):\n",
        "            for dir in dirs:\n",
        "                subdir_path = os.path.join(root, dir)\n",
        "                # print(subdir_path)\n",
        "                for file in os.listdir(subdir_path):\n",
        "                    if file.endswith(\".ply\"):\n",
        "                        # print(os.path.join(subdir_path, file))\n",
        "                        file_paths.append(os.path.join(subdir_path, file))\n",
        "        return file_paths\n",
        "    def __len__(self):\n",
        "        return len(self.file_paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        ply_data = load_ply(self.file_paths[idx])\n",
        "        points = torch.tensor(ply_data, dtype=torch.float32)\n",
        "        return points\n"
      ],
      "metadata": {
        "id": "tJc1a3jjB5ks"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch.utils.data import Subset\n",
        "\n",
        "\n",
        "drive_root = '/content/drive/MyDrive/RLFinalProjectFiles'\n",
        "org_root = os.path.join(drive_root, 'shape_net_core_uniform_samples_2048')\n",
        "\n",
        "del_ratio = 50\n",
        "\n",
        "# Define data loaders (using only train and test loaders)\n",
        "batch_size = 1\n",
        "train_data = PointCloudDataset(os.path.join(org_root + '_pointsremoved', 'train', str(del_ratio)))\n",
        "test_data = PointCloudDataset(os.path.join(org_root + '_pointsremoved', 'test', str(del_ratio)))\n",
        "\n",
        "print(train_data[0])\n",
        "\n",
        "test_indices = list(range(len(test_data)))\n",
        "val_indices, test_indices = train_test_split(test_indices, test_size=0.5, random_state=42)\n",
        "\n",
        "# Define datasets for validation and test\n",
        "validation_data = Subset(test_data, val_indices)\n",
        "test_data = Subset(test_data, test_indices)\n"
      ],
      "metadata": {
        "id": "lgjiIDlDCAs7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dc423366-9948-4e96-a4b4-b4f264fa6a53"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 0.0080, -0.2378, -0.3604],\n",
            "        [ 0.1333, -0.2293, -0.3604],\n",
            "        [ 0.1775, -0.2266, -0.3604],\n",
            "        ...,\n",
            "        [ 0.1860, -0.2369,  0.3603],\n",
            "        [ 0.1272, -0.2443,  0.3604],\n",
            "        [ 0.1489, -0.2411,  0.3604]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Encoder Decoder Definition"
      ],
      "metadata": {
        "id": "vagTuSM4V_z_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import torch\n",
        "# import torch.nn as nn\n",
        "# import torch.nn.functional as F\n",
        "\n",
        "# class Encoder(nn.Module):\n",
        "#     def __init__(self, num_points):\n",
        "#         super(Encoder, self).__init__()\n",
        "#         self.num_points = num_points\n",
        "\n",
        "#         self.encoder_conv1 = nn.Conv1d(3, 64, 1)\n",
        "#         self.encoder_conv2 = nn.Conv1d(64, 128, 1)\n",
        "#         self.encoder_fc1 = nn.Linear(128 * num_points, 1024)\n",
        "#         self.encoder_fc2 = nn.Linear(1024, 256)\n",
        "\n",
        "#         #  # Cast weight tensor and bias tensor to Double data type\n",
        "#         # self.encoder_conv1.weight.data = self.encoder_conv1.weight.data.double()\n",
        "#         # self.encoder_conv1.bias.data = self.encoder_conv1.bias.data.double()\n",
        "#         # self.encoder_conv2.weight.data = self.encoder_conv2.weight.data.double()\n",
        "#         # self.encoder_conv2.bias.data = self.encoder_conv2.bias.data.double()\n",
        "\n",
        "#     def forward(self, x):\n",
        "#         x = x.to(self.encoder_conv1.bias.dtype)\n",
        "#         x = F.relu(self.encoder_conv1(x))\n",
        "#         x = F.relu(self.encoder_conv2(x))\n",
        "#         x = x.view(-1, 128 * self.num_points)\n",
        "#         x = F.relu(self.encoder_fc1(x))\n",
        "#         x = F.relu(self.encoder_fc2(x))\n",
        "#         return x\n",
        "\n",
        "# class Decoder(nn.Module):\n",
        "#     def __init__(self, num_points):\n",
        "#         super(Decoder, self).__init__()\n",
        "#         self.num_points = num_points\n",
        "\n",
        "#         self.decoder_fc1 = nn.Linear(256, 1024)\n",
        "#         self.decoder_fc2 = nn.Linear(1024, 128 * num_points)\n",
        "#         self.decoder_conv1 = nn.Conv1d(128, 64, 1)\n",
        "#         self.decoder_conv2 = nn.Conv1d(64, 3, 1)\n",
        "\n",
        "#     def forward(self, x):\n",
        "#         x = F.relu(self.decoder_fc1(x))\n",
        "#         x = F.relu(self.decoder_fc2(x))\n",
        "#         x = x.view(-1, 128, self.num_points)\n",
        "#         x = F.relu(self.decoder_conv1(x))\n",
        "#         x = self.decoder_conv2(x)\n",
        "#         return x"
      ],
      "metadata": {
        "id": "1Eub70lbV_NI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### VAE class"
      ],
      "metadata": {
        "id": "ytc_LFnyRQ2F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class PointCloudVariationalAutoencoder(nn.Module):\n",
        "    def __init__(self, num_points, latent_dim):\n",
        "        super(PointCloudVariationalAutoencoder, self).__init__()\n",
        "        self.num_points = num_points\n",
        "        self.latent_dim = latent_dim\n",
        "\n",
        "        # Encoder\n",
        "        self.encoder_conv1 = nn.Conv1d(3, 64, 1)\n",
        "        self.encoder_conv2 = nn.Conv1d(64, 128, 1)\n",
        "        self.encoder_fc1 = nn.Linear(128 * num_points, 2048)\n",
        "        self.encoder_fc2_mean = nn.Linear(2048, latent_dim)\n",
        "        self.encoder_fc2_logvar = nn.Linear(2048, latent_dim)\n",
        "\n",
        "        # Decoder\n",
        "        self.decoder_fc1 = nn.Linear(latent_dim, 2048)\n",
        "        self.decoder_fc2 = nn.Linear(2048, 128 * num_points)\n",
        "        self.decoder_conv1 = nn.Conv1d(128, 64, 1)\n",
        "        self.decoder_conv2 = nn.Conv1d(64, 3, 1)\n",
        "\n",
        "        # Upsampling layer for encoder\n",
        "        self.upsample = nn.ConvTranspose1d(128, 64, kernel_size=4, stride=2, padding=1, output_padding=0)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Encoder\n",
        "        x = F.relu(self.encoder_conv1(x))\n",
        "        x = F.relu(self.encoder_conv2(x))\n",
        "        if x.size(-1) == 1024:  # Check if input size is 1024\n",
        "            x = self.upsample(x)\n",
        "        x = x.view(-1, 128 * self.num_points)\n",
        "        x = F.relu(self.encoder_fc1(x))\n",
        "        z_mean = self.encoder_fc2_mean(x)\n",
        "        z_logvar = self.encoder_fc2_logvar(x)\n",
        "\n",
        "        # Reparameterization trick\n",
        "        epsilon = torch.randn_like(z_logvar)\n",
        "        z = z_mean + torch.exp(0.5 * z_logvar) * epsilon\n",
        "\n",
        "        # Decoder\n",
        "        x = F.relu(self.decoder_fc1(z))\n",
        "        x = F.relu(self.decoder_fc2(x))\n",
        "        x = x.view(-1, 128, self.num_points)\n",
        "        x = F.relu(self.decoder_conv1(x))\n",
        "        x = self.decoder_conv2(x)\n",
        "\n",
        "        return x, z\n",
        "\n",
        "    def get_encoder(self):\n",
        "        return Encoder(self.num_points, self.latent_dim)\n",
        "\n",
        "    def get_decoder(self):\n",
        "        return Decoder()\n",
        "\n",
        "class Encoder(nn.Module):\n",
        "    def __init__(self, num_points, latent_dim):\n",
        "        super(Encoder, self).__init__()\n",
        "        self.num_points = num_points\n",
        "        self.latent_dim = latent_dim\n",
        "\n",
        "        self.encoder_conv1 = nn.Conv1d(3, 64, 1)\n",
        "        self.encoder_conv2 = nn.Conv1d(64, 128, 1)\n",
        "        self.encoder_fc1 = nn.Linear(128 * num_points, 2048)\n",
        "        self.encoder_fc2_mean = nn.Linear(2048, latent_dim)\n",
        "        self.encoder_fc2_logvar = nn.Linear(2048, latent_dim)\n",
        "\n",
        "        # Upsampling layer for encoder\n",
        "        self.upsample = nn.ConvTranspose1d(128, 64, kernel_size=4, stride=2, padding=1, output_padding=0)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.encoder_conv1(x))\n",
        "        x = F.relu(self.encoder_conv2(x))\n",
        "        if x.size(-1) == 1024:  # Check if input size is 1024\n",
        "            x = self.upsample(x)\n",
        "        x = x.view(-1, 128 * self.num_points)\n",
        "        x = F.relu(self.encoder_fc1(x))\n",
        "        z_mean = self.encoder_fc2_mean(x)\n",
        "        z_logvar = self.encoder_fc2_logvar(x)\n",
        "        return z_mean, z_logvar\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Decoder, self).__init__()\n",
        "        self.feature_num = 256\n",
        "        self.output_point_number = 2048\n",
        "\n",
        "        self.linear1 = nn.Linear(self.feature_num, self.output_point_number*2)\n",
        "        self.linear2 = nn.Linear(self.output_point_number*2, self.output_point_number*3)\n",
        "        self.linear3 = nn.Linear(self.output_point_number*3, self.output_point_number*4)\n",
        "        self.linear_out = nn.Linear(self.output_point_number*4, self.output_point_number*3)\n",
        "\n",
        "        # Special initialization for linear_out to get a uniform distribution over the space\n",
        "        self.linear_out.bias.data.uniform_(-1, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Reshape from feature vector NxC to NxC\n",
        "        x = F.relu(self.linear1(x))\n",
        "        x = F.relu(self.linear2(x))\n",
        "        x = F.relu(self.linear3(x))\n",
        "        x = self.linear_out(x)\n",
        "\n",
        "        return x.view(-1, 3, self.output_point_number)\n"
      ],
      "metadata": {
        "id": "jPnKTwsqRTKO"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Generator Discriminator Definition"
      ],
      "metadata": {
        "id": "bF1Ukbd_WJBM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "\n",
        "class Generator(nn.Module):\n",
        "    \"\"\"Generator.\"\"\"\n",
        "\n",
        "    def __init__(self, z_dim=1, gfvs_dim=256, conv_dim=64):\n",
        "        super(Generator, self).__init__()\n",
        "        self.gfvs_dim = gfvs_dim\n",
        "\n",
        "        # Calculate the initial image width based on the GFVs shape\n",
        "        self.initial_image_width = int(gfvs_dim / (conv_dim * 4))\n",
        "\n",
        "        # Adjust the input dimension to match the latent vector size\n",
        "        self.fc = nn.Linear(z_dim, conv_dim * 8 * self.initial_image_width)\n",
        "\n",
        "        # Define the convolutional layers\n",
        "        self.conv1 = nn.ConvTranspose2d(conv_dim * 8, conv_dim * 4, 4, 2, 1)\n",
        "        self.conv2 = nn.ConvTranspose2d(conv_dim * 4, conv_dim * 2, 4, 2, 1)\n",
        "        self.conv3 = nn.ConvTranspose2d(conv_dim * 2, conv_dim, 4, 2, 1)\n",
        "        self.conv4 = nn.ConvTranspose2d(conv_dim, 1, 4, 2, 1)\n",
        "\n",
        "    def forward(self, z):\n",
        "        out = self.fc(z)\n",
        "        out = out.view(-1, 64 * 8, self.initial_image_width, 1)\n",
        "        out = F.relu(self.conv1(out))\n",
        "        out = F.relu(self.conv2(out))\n",
        "        out = F.relu(self.conv3(out))\n",
        "        out = torch.tanh(self.conv4(out))  # Apply tanh activation for image generation\n",
        "        return out\n",
        "\n",
        "\n",
        "class Discriminator(nn.Module):\n",
        "    \"\"\"Discriminator.\"\"\"\n",
        "\n",
        "    def __init__(self, gfvs_dim=256, conv_dim=64):\n",
        "        super(Discriminator, self).__init__()\n",
        "        self.gfvs_dim = gfvs_dim\n",
        "\n",
        "        # Calculate the final image size based on the GFVs shape\n",
        "        self.final_image_size = int(np.sqrt(gfvs_dim/ conv_dim / 4))\n",
        "\n",
        "        # Adjust the input dimension to match the GFVs size\n",
        "        self.conv1 = nn.Conv2d(1, conv_dim, 4)\n",
        "        self.conv2 = nn.Conv2d(conv_dim, conv_dim * 2, 4, 2, 1)\n",
        "        self.conv3 = nn.Conv2d(conv_dim * 2, conv_dim * 4, 4, 2, 1)\n",
        "        self.conv4 = nn.Conv2d(conv_dim * 4, 1, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = F.leaky_relu(self.conv1(x), 0.2)\n",
        "        out = F.leaky_relu(self.conv2(out), 0.2)\n",
        "        out = F.leaky_relu(self.conv3(out), 0.2)\n",
        "        out = self.conv4(out)\n",
        "        return out.squeeze()  # Return a 1D output\n"
      ],
      "metadata": {
        "id": "ghnozjhVWOKF"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Generator Discriminator with Self Attention"
      ],
      "metadata": {
        "id": "2-mP1xvrRXgY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import torch\n",
        "# import torch.nn as nn\n",
        "# import torch.nn.functional as F\n",
        "# import numpy as np\n",
        "\n",
        "# class SelfAttention(nn.Module):\n",
        "#     \"\"\"Self Attention Layer.\"\"\"\n",
        "\n",
        "#     def __init__(self, in_dim):\n",
        "#         super(SelfAttention, self).__init__()\n",
        "\n",
        "#         self.query_conv = nn.Conv2d(in_channels=in_dim, out_channels=in_dim//8, kernel_size=1)\n",
        "#         self.key_conv = nn.Conv2d(in_channels=in_dim, out_channels=in_dim//8, kernel_size=1)\n",
        "#         self.value_conv = nn.Conv2d(in_channels=in_dim, out_channels=in_dim, kernel_size=1)\n",
        "#         self.gamma = nn.Parameter(torch.zeros(1))\n",
        "\n",
        "#     def forward(self, x):\n",
        "#         batch, channels, height, width = x.size()\n",
        "\n",
        "#         proj_query = self.query_conv(x).view(batch, -1, height*width).permute(0, 2, 1)\n",
        "#         proj_key = self.key_conv(x).view(batch, -1, height*width)\n",
        "\n",
        "#         energy = torch.bmm(proj_query, proj_key)\n",
        "#         attention = F.softmax(energy, dim=-1)\n",
        "\n",
        "#         proj_value = self.value_conv(x).view(batch, -1, height*width)\n",
        "\n",
        "#         out = torch.bmm(proj_value, attention.permute(0, 2, 1))\n",
        "#         out = out.view(batch, channels, height, width)\n",
        "\n",
        "#         out = self.gamma * out + x\n",
        "#         return out\n",
        "\n",
        "# class Generator(nn.Module):\n",
        "#     \"\"\"Generator.\"\"\"\n",
        "\n",
        "#     def __init__(self, z_dim=1, gfvs_dim=256, conv_dim=64):\n",
        "#         super(Generator, self).__init__()\n",
        "#         self.gfvs_dim = gfvs_dim\n",
        "\n",
        "#         # Calculate the initial image size based on the GFVs shape\n",
        "#         self.initial_image_size = int(np.sqrt(gfvs_dim / conv_dim / 4))\n",
        "\n",
        "#         # Adjust the input dimension to match the latent vector size\n",
        "#         self.fc = nn.Linear(z_dim, conv_dim * 8 * self.initial_image_size * self.initial_image_size)\n",
        "\n",
        "#         # Define the convolutional layers\n",
        "#         self.conv1 = nn.ConvTranspose2d(conv_dim * 8, conv_dim * 4, 4, 2, 1)\n",
        "#         self.sa1 = SelfAttention(conv_dim * 4)\n",
        "#         self.conv2 = nn.ConvTranspose2d(conv_dim * 4, conv_dim * 2, 4, 2, 1)\n",
        "#         self.sa2 = SelfAttention(conv_dim * 2)\n",
        "#         self.conv3 = nn.ConvTranspose2d(conv_dim * 2, conv_dim, 4, 2, 1)\n",
        "#         self.sa3 = SelfAttention(conv_dim)\n",
        "#         self.conv4 = nn.ConvTranspose2d(conv_dim , 1, 4, 2, 1)  # Output should match GFVs size\n",
        "#         self.fc_output = nn.Linear(conv_dim * self.initial_image_size * self.initial_image_size, gfvs_dim)\n",
        "\n",
        "#     def forward(self, z):\n",
        "#         out = self.fc(z)\n",
        "#         out = out.view(-1, 64 * 8, self.initial_image_size, self.initial_image_size)\n",
        "#         out = F.relu(self.conv1(out))\n",
        "#         out = self.sa1(out)\n",
        "#         out = F.relu(self.conv2(out))\n",
        "#         out = self.sa2(out)\n",
        "#         out = F.relu(self.conv3(out))\n",
        "#         out = self.sa3(out)\n",
        "#         out = torch.tanh(self.conv4(out))  # Apply tanh activation for image generation\n",
        "#         # out = out.squeeze()  # Flatten the output\n",
        "#         out = out.permute(0, 2, 3, 1)\n",
        "#         out = out.view(-1, 64 * self.initial_image_size * self.initial_image_size) # Reshape to match GFVs dimension\n",
        "#         return out\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# class Discriminator(nn.Module):\n",
        "#     \"\"\"Discriminator.\"\"\"\n",
        "\n",
        "#     def __init__(self, gfvs_dim=256, conv_dim=64):\n",
        "#         super(Discriminator, self).__init__()\n",
        "#         self.gfvs_dim = gfvs_dim\n",
        "\n",
        "#         # Calculate the final image size based on the GFVs shape\n",
        "#         self.final_image_size = int(np.sqrt(gfvs_dim/ conv_dim / 4))\n",
        "\n",
        "#         # Adjust the input dimension to match the GFVs size\n",
        "#         self.conv1 = nn.Conv2d(1, conv_dim, 1)\n",
        "#         self.conv2 = nn.Conv2d(conv_dim, conv_dim * 2, 3, 2, 1)\n",
        "#         self.sa1 = SelfAttention(conv_dim * 2)\n",
        "#         self.conv3 = nn.Conv2d(conv_dim * 2, conv_dim * 4, 3, 2, 1)\n",
        "#         self.sa2 = SelfAttention(conv_dim * 4)\n",
        "#         self.conv4 = nn.Conv2d(conv_dim * 4, 1, 1)\n",
        "\n",
        "#     def forward(self, x):\n",
        "#         out = F.leaky_relu(self.conv1(x), 0.2)\n",
        "#         out = F.leaky_relu(self.conv2(out), 0.2)\n",
        "#         out = self.sa1(out)\n",
        "#         out = F.leaky_relu(self.conv3(out), 0.2)\n",
        "#         out = self.sa2(out)\n",
        "#         out = self.conv4(out)\n",
        "#         return out.squeeze()  # Return a 1D output\n"
      ],
      "metadata": {
        "id": "yvGT--v9RcAH"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Reading saved AE, Generator and Discriminator models"
      ],
      "metadata": {
        "id": "DZA897iNV90i"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "GsdOwlLAV7KB"
      },
      "outputs": [],
      "source": [
        "model_dir = '/content/drive/MyDrive/RLFinalProjectFiles/models/'\n",
        "\n",
        "encoder_state_dict = torch.load(model_dir + \"vae_encoder3.pth\")  # Load encoder weights\n",
        "# encoder.eval()  # Set encoder to evaluation mode\n",
        "\n",
        "decoder_state_dict = torch.load(model_dir + \"vae_decoder3.pth\")  # Load encoder weights\n",
        "# decoder.eval()  # Set encoder to evaluation mode\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Training RL agent using pretrained enc, dec, gen & dis"
      ],
      "metadata": {
        "id": "uOlFNj0fnGrF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pc_dim = 2048\n",
        "z_dim = 1\n",
        "\n",
        "autoencoder = PointCloudVariationalAutoencoder(num_points=2048, latent_dim=256)\n",
        "autoencoder.get_encoder().load_state_dict(encoder_state_dict)\n",
        "autoencoder.get_decoder().load_state_dict(decoder_state_dict)\n",
        "\n",
        "autoencoder.eval()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qazSGFhESw8L",
        "outputId": "cb9bb5a2-5231-4e18-c426-d5dc30cca337"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PointCloudVariationalAutoencoder(\n",
              "  (encoder_conv1): Conv1d(3, 64, kernel_size=(1,), stride=(1,))\n",
              "  (encoder_conv2): Conv1d(64, 128, kernel_size=(1,), stride=(1,))\n",
              "  (encoder_fc1): Linear(in_features=262144, out_features=2048, bias=True)\n",
              "  (encoder_fc2_mean): Linear(in_features=2048, out_features=256, bias=True)\n",
              "  (encoder_fc2_logvar): Linear(in_features=2048, out_features=256, bias=True)\n",
              "  (decoder_fc1): Linear(in_features=256, out_features=2048, bias=True)\n",
              "  (decoder_fc2): Linear(in_features=2048, out_features=262144, bias=True)\n",
              "  (decoder_conv1): Conv1d(128, 64, kernel_size=(1,), stride=(1,))\n",
              "  (decoder_conv2): Conv1d(64, 3, kernel_size=(1,), stride=(1,))\n",
              "  (upsample): ConvTranspose1d(128, 64, kernel_size=(4,), stride=(2,), padding=(1,))\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gen_state_dict = torch.load(model_dir + \"generator1.pth\")  # Load generator weights\n",
        "  # Set generator to evaluation mode\n",
        "\n",
        "disc_state_dict = torch.load(model_dir + \"discriminator1.pth\")  # Load decoder weights\n"
      ],
      "metadata": {
        "id": "DKZ5TcteWE-M"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generator = Generator(z_dim=1, gfvs_dim=256, conv_dim=64)\n",
        "discriminator = Discriminator(gfvs_dim=256)\n",
        "\n",
        "generator.load_state_dict(gen_state_dict)\n",
        "discriminator.load_state_dict(disc_state_dict)\n",
        "\n",
        "# generator.eval()\n",
        "# discriminator.eval()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "St801VsMe3Zb",
        "outputId": "55f5d637-8ff4-4b27-e238-53bee491b6b1"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# enc_output = autoencoder.get_encoder()(torch.tensor(train_data))\n",
        "fixed_z = torch.randn(1, z_dim)\n",
        "gen_out = generator(fixed_z)\n",
        "print(gen_out.shape)\n",
        "gen_out = gen_out.view(1,256)\n",
        "dec_output = autoencoder.get_decoder()(gen_out)\n",
        "dec_output"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aL6qQ1usfzWq",
        "outputId": "901cea1c-db0e-498b-97cf-00e4314dc0b4"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 1, 16, 16])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[-0.0174,  0.9913, -0.7400,  ...,  0.9463,  0.5616,  0.7763],\n",
              "         [ 0.7197, -0.3247, -0.2558,  ...,  0.9189,  0.0347,  0.7379],\n",
              "         [-0.9667, -0.2978,  0.4626,  ...,  0.6799,  0.2097,  0.2638]]],\n",
              "       grad_fn=<ViewBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Visualise decoder output"
      ],
      "metadata": {
        "id": "4iEfZVDgZE2J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "\n",
        "def visualize_point_cloud(point_cloud):\n",
        "    fig = plt.figure()\n",
        "    ax = fig.add_subplot(111, projection='3d')\n",
        "    ax.scatter(point_cloud[:, 0], point_cloud[:, 1], point_cloud[:, 2], s=1)\n",
        "    ax.set_xlabel('X')\n",
        "    ax.set_ylabel('Y')\n",
        "    ax.set_zlabel('Z')\n",
        "    plt.show()\n",
        "\n",
        "# Example usage:\n",
        "# Visualize a point cloud from the train dataset\n",
        "example_point_cloud = dec_output.detach().numpy()\n",
        "print(\"count of points: \",len(example_point_cloud))\n",
        "visualize_point_cloud(example_point_cloud)\n",
        "# visualize_point_cloud(train_data[0].detach().numpy())"
      ],
      "metadata": {
        "id": "PQJfA_fNZEgG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 433
        },
        "outputId": "d3a35b43-7c4f-407b-d55e-df83474a9553"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "count of points:  1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chamfer Loss function"
      ],
      "metadata": {
        "id": "jFwqD5awErBr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install faiss-cpu"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fe38rGDJE1l1",
        "outputId": "89cd5086-2ee2-4bdb-ed92-dc5e9b2a88d8"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting faiss-cpu\n",
            "  Downloading faiss_cpu-1.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (27.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m27.0/27.0 MB\u001b[0m \u001b[31m48.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from faiss-cpu) (1.25.2)\n",
            "Installing collected packages: faiss-cpu\n",
            "Successfully installed faiss-cpu-1.8.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import faiss\n",
        "\n",
        "def robust_norm(var):\n",
        "    '''\n",
        "    :param var: Variable of BxCxHxW\n",
        "    :return: p-norm of BxCxW\n",
        "    '''\n",
        "    result = ((var**2).sum(dim=2) + 1e-8).sqrt()\n",
        "    # result = (var ** 2).sum(dim=2)\n",
        "\n",
        "    # try to make the points less dense, caused by the backward loss\n",
        "    # result = result.clamp(min=7e-3, max=None)\n",
        "    return result\n",
        "\n",
        "class ChamferLoss(nn.Module):\n",
        "    def __init__(self, opt):\n",
        "        super(ChamferLoss, self).__init__()\n",
        "        self.opt = opt\n",
        "        self.dimension = 3\n",
        "        self.k = 1\n",
        "\n",
        "        # we need only a StandardGpuResources per GPU\n",
        "        # self.res = faiss.StandardGpuResources()\n",
        "        # self.res.setTempMemoryFraction(0.1)\n",
        "\n",
        "        # place holder\n",
        "        self.forward_loss = torch.FloatTensor([0])\n",
        "        self.backward_loss = torch.FloatTensor([0])\n",
        "\n",
        "    def build_nn_index(self, database):\n",
        "        '''\n",
        "        :param database: numpy array of Nx3\n",
        "        :return: Faiss index, in CPU\n",
        "        '''\n",
        "        index = faiss.IndexFlatL2(self.dimension)\n",
        "        index.add(database)\n",
        "        return index\n",
        "\n",
        "    def search_nn(self, index, query, k):\n",
        "        '''\n",
        "        :param index: Faiss index\n",
        "        :param query: numpy array of Nx3\n",
        "        :return: D: Variable of Nxk, type FloatTensor, in CPU\n",
        "                 I: Variable of Nxk, type LongTensor, in CPU\n",
        "        '''\n",
        "        D, I = index.search(query, k)\n",
        "\n",
        "        D_var = torch.from_numpy(np.ascontiguousarray(D))\n",
        "        I_var = torch.from_numpy(np.ascontiguousarray(I).astype(np.int64))\n",
        "\n",
        "        return D_var, I_var\n",
        "\n",
        "    def forward(self, predict_pc, gt_pc):\n",
        "        '''\n",
        "        :param predict_pc: Bx3xM Variable in CPU\n",
        "        :param gt_pc: Bx3xN Variable in CPU\n",
        "        :return:\n",
        "        '''\n",
        "\n",
        "        predict_pc_size = predict_pc.size()\n",
        "        gt_pc_size = gt_pc.size()\n",
        "\n",
        "        predict_pc_np = np.ascontiguousarray(torch.transpose(predict_pc.data.clone(), 1, 2).numpy())  # BxMx3\n",
        "        gt_pc_np = np.ascontiguousarray(torch.transpose(gt_pc.data.clone(), 1, 2).numpy())  # BxNx3\n",
        "\n",
        "        # selected_gt: Bxkx3xM\n",
        "        selected_gt_by_predict = torch.FloatTensor(predict_pc_size[0], self.k, predict_pc_size[1], predict_pc_size[2])\n",
        "        # selected_predict: Bxkx3xN\n",
        "        selected_predict_by_gt = torch.FloatTensor(gt_pc_size[0], self.k, gt_pc_size[1], gt_pc_size[2])\n",
        "\n",
        "        # process each batch independently.\n",
        "        for i in range(predict_pc_np.shape[0]):\n",
        "            index_predict = self.build_nn_index(predict_pc_np[i])\n",
        "            index_gt = self.build_nn_index(gt_pc_np[i])\n",
        "\n",
        "            # database is gt_pc, predict_pc -> gt_pc -----------------------------------------------------------\n",
        "            _, I_var = self.search_nn(index_gt, predict_pc_np[i], self.k)\n",
        "\n",
        "            # process nearest k neighbors\n",
        "            for k in range(self.k):\n",
        "                selected_gt_by_predict[i,k,...] = gt_pc[i].index_select(1, I_var[:,k])\n",
        "\n",
        "            # database is predict_pc, gt_pc -> predict_pc -------------------------------------------------------\n",
        "            _, I_var = self.search_nn(index_predict, gt_pc_np[i], self.k)\n",
        "\n",
        "            # process nearest k neighbors\n",
        "            for k in range(self.k):\n",
        "                selected_predict_by_gt[i,k,...] = predict_pc[i].index_select(1, I_var[:,k])\n",
        "\n",
        "        # compute loss ===================================================\n",
        "        # selected_gt(Bxkx3xM) vs predict_pc(Bx3xM)\n",
        "        forward_loss_element = robust_norm(selected_gt_by_predict-predict_pc.unsqueeze(1).expand_as(selected_gt_by_predict))\n",
        "        self.forward_loss = forward_loss_element.mean()\n",
        "        self.forward_loss_array = forward_loss_element.mean(dim=1).mean(dim=1)\n",
        "\n",
        "        # selected_predict(Bxkx3xN) vs gt_pc(Bx3xN)\n",
        "        backward_loss_element = robust_norm(selected_predict_by_gt - gt_pc.unsqueeze(1).expand_as(selected_predict_by_gt))  # BxkxN\n",
        "        self.backward_loss = backward_loss_element.mean()\n",
        "        self.backward_loss_array = backward_loss_element.mean(dim=1).mean(dim=1)\n",
        "\n",
        "        # self.loss_array = self.forward_loss_array + self.backward_loss_array\n",
        "        return self.forward_loss + self.backward_loss # + self.sparsity_loss\n",
        "\n",
        "    def __call__(self, predict_pc, gt_pc):\n",
        "        # start_time = time.time()\n",
        "        loss = self.forward(predict_pc, gt_pc)\n",
        "        # print(time.time()-start_time)\n",
        "        return loss\n"
      ],
      "metadata": {
        "id": "yLIOijP4EuaD"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### MSE, NLL, Norm"
      ],
      "metadata": {
        "id": "1-V6ZObgFZYG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class NLL(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(NLL,self).__init__()\n",
        "    def forward(self,x):\n",
        "     #   neglog = - F.log_softmax(x,dim=0)\n",
        "        # greater the value greater the chance of being real\n",
        "        #probe = torch.mean(-F.log_softmax(x,dim=0))#F.softmax(x,dim=0)\n",
        "\n",
        "      #  print(x.cpu().data.n/umpy())\n",
        "       # print(-torch.log(x).cpu().data.numpy())\n",
        "        return torch.mean(x)\n",
        "\n",
        "class MSE(nn.Module):\n",
        "    def __init__(self,reduction = 'elementwise_mean'):\n",
        "        super(MSE,self).__init__()\n",
        "        self.reduction = reduction\n",
        "    def forward(self,x,y):\n",
        "        mse = F.mse_loss(x,y,reduction =self.reduction)\n",
        "        return mse\n",
        "\n",
        "\n",
        "class Norm(nn.Module):\n",
        "    def __init__(self,dims):\n",
        "        super(Norm,self).__init__()\n",
        "        self.dims =dims\n",
        "\n",
        "    def forward(self,x):\n",
        "        z2 = torch.norm(x,p=2)\n",
        "        out = (z2-self.dims)\n",
        "        out = out*out\n",
        "        return out\n",
        "\n",
        "class AverageMeter(object):\n",
        "    \"\"\"Computes and stores the average and current value\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.reset()\n",
        "\n",
        "    def reset(self):\n",
        "        self.val = 0\n",
        "        self.avg = 0\n",
        "        self.sum = 0\n",
        "        self.count = 0\n",
        "\n",
        "    def update(self, val, n=1):\n",
        "        self.val = val\n",
        "        self.sum += val * n\n",
        "        self.count += n\n",
        "        self.avg = self.sum / self.count\n",
        "\n",
        "    def __repr__(self):\n",
        "        return '{:.3f} ({:.3f})'.format(self.val, self.avg)"
      ],
      "metadata": {
        "id": "kf5Eog-wFdr4"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### DDPG Implementation\n",
        "\n"
      ],
      "metadata": {
        "id": "_IWqaFkYGAYw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.autograd import Variable\n",
        "import torch.nn.functional as F\n",
        "from collections import OrderedDict\n",
        "\n",
        "device = torch.device(\"cpu\")#(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Implementation of Deep Deterministic Policy Gradients (DDPG)\n",
        "# Paper: https://arxiv.org/abs/1509.02971\n",
        "\n",
        "class ReplayBuffer(object):\n",
        "\tdef __init__(self):\n",
        "\t\tself.storage = []\n",
        "\n",
        "\t# Expects tuples of (state, next_state, action, reward, done)\n",
        "\tdef add(self, data):\n",
        "\t\tself.storage.append(data)\n",
        "\n",
        "\tdef sample(self, batch_size=79):\n",
        "\t\t\tx, y, u, r, d = [], [], [], [], []\n",
        "\n",
        "\t\t\tfor _ in range(batch_size):\n",
        "\t\t\t\t\t\tidx = np.random.randint(0, len(self.storage))\n",
        "\t\t\t\t\t\tX, Y, U, R, D = self.storage[idx]\n",
        "\n",
        "\t\t\t\t\t\tx.append(X)\n",
        "\t\t\t\t\t\ty.append(Y)\n",
        "\t\t\t\t\t\tu.append(U)\n",
        "\t\t\t\t\t\tr.append(R)\n",
        "\t\t\t\t\t\td.append(D)\n",
        "\n",
        "\t\t\t# Convert lists to numpy arrays\n",
        "\t\t\tx = np.array(x)\n",
        "\t\t\ty = np.array(y)\n",
        "\t\t\tu = np.array(u)#.reshape(-1, 1)  # Reshape u, r, and d to match (batch_size, 1) shape\n",
        "\t\t\tr = np.array(r).reshape(-1, 1)\n",
        "\t\t\td = np.array(d).reshape(-1, 1)\n",
        "\n",
        "\t\t\treturn x, y, u, r, d\n",
        "\n",
        "\n",
        "class Actor(nn.Module):\n",
        "\tdef __init__(self, state_dim, action_dim, max_action):\n",
        "\t\tsuper(Actor, self).__init__()\n",
        "\n",
        "\t\tself.l1 = nn.Linear(state_dim, 400)#400\n",
        "\t\tself.l2 = nn.Linear(400, 400)\n",
        "\t\tself.l2_additional = nn.Linear(400, 300)\n",
        "\t\tself.l3 = nn.Linear(300, action_dim)\n",
        "\n",
        "\t\tself.max_action = max_action\n",
        "\n",
        "\n",
        "\tdef forward(self, x):\n",
        "\t\tx = F.relu(self.l1(x))\n",
        "\t\tx = F.relu(self.l2(x))\n",
        "\t\tx = F.relu(self.l2_additional(x))\n",
        "\t\tx = self.max_action * torch.tanh(self.l3(x))\n",
        "\t\treturn x\n",
        "\n",
        "\n",
        "class Critic(nn.Module):\n",
        "    def __init__(self, state_dim, action_dim):\n",
        "        super(Critic, self).__init__()\n",
        "\n",
        "        self.l1 = nn.Linear(state_dim, 400)\n",
        "        self.l2 = nn.Linear(400 + action_dim, 300)\n",
        "        self.l3_additional = nn.Linear(300, 300)\n",
        "        self.l3 = nn.Linear(300, 1)\n",
        "\n",
        "    def forward(self, x, u):\n",
        "        x = F.relu(self.l1(x))\n",
        "        # print(\"x size: \",x.size())\n",
        "        # print(\"u size: \"u.size())\n",
        "        # u = u.view(u.size(0), -1)\n",
        "        # x = x.squeeze(1)\n",
        "        # u = u.squeeze(1)\n",
        "        x = F.relu(self.l2(torch.cat([x, u], 2)))\n",
        "        x = self.l3_additional(x)\n",
        "        x = self.l3(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "\n",
        "class DDPG(object):\n",
        "\tdef __init__(self, state_dim, action_dim, max_action,device):\n",
        "\t\tself.device = device\n",
        "\t\tself.actor = Actor(state_dim, action_dim, max_action).to(device)\n",
        "\t\tself.actor_target = Actor(state_dim, action_dim, max_action).to(device)\n",
        "\t\tself.actor_target.load_state_dict(self.actor.state_dict())\n",
        "\t\tself.actor_optimizer = torch.optim.Adam(self.actor.parameters(), lr=1e-4)\n",
        "\n",
        "\t\tself.critic = Critic(state_dim, action_dim).to(device)\n",
        "\t\tself.critic_target = Critic(state_dim, action_dim).to(device)\n",
        "\t\tself.critic_target.load_state_dict(self.critic.state_dict())\n",
        "\t\tself.critic_optimizer = torch.optim.Adam(self.critic.parameters(), weight_decay=1e-2)\n",
        "\n",
        "\n",
        "\tdef select_action(self, state):\n",
        "\t\t# state = torch.FloatTensor(state.reshape(batch_size, state_dim)).to(device)\n",
        "\t\tstate = torch.FloatTensor(state).to(device)\n",
        "\t\t# print(\"state shape: \",state.shape)\n",
        "\t\treturn self.actor(state).data.numpy().flatten()\n",
        "\n",
        "\n",
        "\tdef train(self, replay_buffer, iterations, batch_size=79, discount=0.99, tau=0.001):\n",
        "\n",
        "\t\tfor it in range(iterations):\n",
        "\n",
        "\t\t\t\t# Sample replay buffer\n",
        "\t\t\t\tx, y, u, r, d = replay_buffer.sample(batch_size)\n",
        "\n",
        "\t\t\t\tstate = torch.FloatTensor(x).to(device)\n",
        "\t\t\t\taction = torch.FloatTensor(u).to(device)\n",
        "\t\t\t\tnext_state = torch.FloatTensor(y).to(device)\n",
        "\t\t\t\tdone = torch.FloatTensor(1 - d).to(device)\n",
        "\t\t\t\treward = torch.FloatTensor(r).to(device)\n",
        "\n",
        "\t\t\t\t# Compute the target Q value\n",
        "\t\t\t\ttarget_Q = self.critic_target(next_state, self.actor_target(next_state))\n",
        "\t\t\t\t# print(\"target Q shape: \",target_Q.shape)\n",
        "\t\t\t\ttarget_Q = reward + (done * discount * target_Q).detach()\n",
        "\n",
        "\t\t\t\t# Get current Q estimate\n",
        "\t\t\t\tcurrent_Q = self.critic(state, action)\n",
        "\n",
        "\t\t\t\t# Compute critic loss\n",
        "\t\t\t\tcritic_loss = F.mse_loss(current_Q, target_Q)\n",
        "\n",
        "\t\t\t\t# Optimize the critic\n",
        "\t\t\t\tself.critic_optimizer.zero_grad()\n",
        "\t\t\t\tcritic_loss.backward()\n",
        "\t\t\t\tself.critic_optimizer.step()\n",
        "\n",
        "\t\t\t\t# Compute actor loss\n",
        "\t\t\t\tactor_loss = -self.critic(state, self.actor(state)).mean()\n",
        "\n",
        "\t\t\t\t# Optimize the actor\n",
        "\t\t\t\tself.actor_optimizer.zero_grad()\n",
        "\t\t\t\tactor_loss.backward()\n",
        "\t\t\t\tself.actor_optimizer.step()\n",
        "\n",
        "\t\t\t\t# Update the frozen target models\n",
        "\t\t\t\tfor param, target_param in zip(self.critic.parameters(), self.critic_target.parameters()):\n",
        "\t\t\t\t\ttarget_param.data.copy_(tau * param.data + (1 - tau) * target_param.data)\n",
        "\n",
        "\t\t\t\tfor param, target_param in zip(self.actor.parameters(), self.actor_target.parameters()):\n",
        "\t\t\t\t\ttarget_param.data.copy_(tau * param.data + (1 - tau) * target_param.data)\n",
        "\n",
        "\n",
        "\tdef save(self, filename, directory):\n",
        "\t\ttorch.save(self.actor.state_dict(), '%s/%s_actor.pth' % (directory, filename))\n",
        "\t\ttorch.save(self.critic.state_dict(), '%s/%s_critic.pth' % (directory, filename))\n",
        "\n",
        "\n",
        "\tdef load(self, filename, directory):\n",
        "\t\tself.actor.load_state_dict(torch.load('%s/%s_actor.pth' % (directory, filename)))\n",
        "\t\tself.critic.load_state_dict(torch.load('%s/%s_critic.pth' % (directory, filename)))"
      ],
      "metadata": {
        "id": "0E5RBArUg6Zc"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import time\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch.utils.data import Subset\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "np.random.seed(5)\n",
        "#torch.manual_seed(5)\n",
        "\n",
        "def evaluate_policy(policy,valid_loader,env, eval_episodes=6,render = False):\n",
        "    print(\"-----------------evaluating---------------\")\n",
        "    avg_reward = 0.\n",
        "    env.reset(epoch_size=30,figures=8) # reset the visdom and set number of figures\n",
        "\n",
        "    #for i,(input) in enumerate(valid_loader):\n",
        "    for i in range (0,eval_episodes):\n",
        "        try:\n",
        "            input = next(dataloader_iterator)\n",
        "        except:\n",
        "            dataloader_iterator = iter(valid_loader)\n",
        "            input = next(dataloader_iterator)\n",
        "\n",
        "        obs =env.agent_input(input)# env(input, action_rand)\n",
        "        done = False\n",
        "\n",
        "        while not done:\n",
        "          # Action By Agent and collect reward\n",
        "            action = policy.select_action(np.array(obs))\n",
        "            action= torch.tensor(action).unsqueeze(dim=0)\n",
        "            new_state, _, reward, done = env( input, action,render=render,disp =True)\n",
        "            avg_reward += reward\n",
        "\n",
        "        if i+1 >= eval_episodes:\n",
        "            break;\n",
        "\n",
        "    avg_reward /= eval_episodes\n",
        "\n",
        "    print(\"---------------------------------------\")\n",
        "    print(\"Evaluation over %d episodes: %f\" % (eval_episodes, avg_reward))\n",
        "    print(\"---------------------------------------\")\n",
        "\n",
        "    return avg_reward\n",
        "\n",
        "def test_policy(policy,valid_loader,env, eval_episodes=12,render = True):\n",
        "    avg_reward = 0.\n",
        "    env.reset(epoch_size=30,figures=12) # reset the visdom and set number of figures\n",
        "\n",
        "    #for i,(input) in enumerate(valid_loader):\n",
        "    for i in range (0,eval_episodes):\n",
        "        try:\n",
        "            input = next(dataloader_iterator)\n",
        "        except:\n",
        "            dataloader_iterator = iter(valid_loader)\n",
        "            input = next(dataloader_iterator)\n",
        "\n",
        "       # data_iter = iter(valid_loader)\n",
        "       # input = data_iter.next()\n",
        "        #action_rand = torch.randn(args.batch_size, args.z_dim)\n",
        "        obs =env.agent_input(input)# env(input, action_rand)\n",
        "        done = False\n",
        "\n",
        "        while not done:\n",
        "          # Action By Agent and collect reward\n",
        "            action = policy.select_action(np.array(obs))\n",
        "            action= torch.tensor(action).unsqueeze(dim=0)\n",
        "            new_state, _, reward, done = env( input, action,render=render,disp =True)\n",
        "            avg_reward += reward\n",
        "\n",
        "        if i+1 >= eval_episodes:\n",
        "            break;\n",
        "\n",
        "    avg_reward /= eval_episodes\n",
        "\n",
        "    print(\"---------------------------------------\")\n",
        "    print(\"Evaluation over %d episodes: %f\" % (eval_episodes, avg_reward))\n",
        "    print(\"---------------------------------------\")\n",
        "\n",
        "    return avg_reward\n",
        "\n",
        "\n",
        "def main():\n",
        "    batch_size = 79\n",
        "\n",
        "    sigma = 0.01\n",
        "    clip = 0.05\n",
        "    def jittered_data(input_data, sigma=0.01, clip=0.05):\n",
        "        jittered_data = []\n",
        "        for input_tensor in input_data:\n",
        "            input_tensor = input_tensor.numpy()\n",
        "            N, C = input_tensor.shape\n",
        "            jitter = np.clip(sigma * np.random.randn(N, C), -1*clip, clip)\n",
        "            jittered = jitter + input_tensor\n",
        "            jittered_data.append(torch.tensor(jittered))\n",
        "        return jittered_data\n",
        "\n",
        "\n",
        "    #Load data\n",
        "    drive_root = '/content/drive/MyDrive/RLFinalProjectFiles'\n",
        "    org_root = os.path.join(drive_root, 'shape_net_core_uniform_samples_2048')\n",
        "\n",
        "    del_ratio = 50\n",
        "\n",
        "    # Define data loaders (using only train and test loaders)\n",
        "    batch_size = 79\n",
        "    z_dim = 1\n",
        "    train_data = PointCloudDataset(os.path.join(org_root + '_pointsremoved', 'train', str(del_ratio)))\n",
        "    print(\"train data length \",len(train_data))\n",
        "    test_data = PointCloudDataset(os.path.join(org_root + '_pointsremoved', 'test', str(del_ratio)))\n",
        "    print(\"test data length \",len(test_data))\n",
        "    dataset = train_data + test_data\n",
        "    data_count = len(train_data) + len(test_data)\n",
        "\n",
        "    train_length = 23*79  # Ensure each part is divisible by 79\n",
        "    remaining_length = data_count - train_length\n",
        "    validation_length = test_length = remaining_length // 2\n",
        "\n",
        "    train_data, remaining_data = random_split(dataset, [train_length, len(dataset) - train_length])\n",
        "    validation_data, test_data = random_split(remaining_data, [validation_length, test_length])\n",
        "\n",
        "\n",
        "    train_data = jittered_data(train_data, sigma=sigma, clip=clip)\n",
        "    validation_data = jittered_data(validation_data, sigma=sigma, clip=clip)\n",
        "    test_data = jittered_data(test_data, sigma=sigma, clip=clip)\n",
        "\n",
        "\n",
        "    train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size,\n",
        "                                               shuffle=True,\n",
        "                                               pin_memory=True)\n",
        "    valid_loader = torch.utils.data.DataLoader(validation_data,\n",
        "                                               batch_size=1,\n",
        "                                               shuffle=False,\n",
        "                                               pin_memory=True)\n",
        "\n",
        "    test_loader = torch.utils.data.DataLoader(test_data,\n",
        "                                               batch_size=1,\n",
        "                                               shuffle=False,\n",
        "                                               pin_memory=True)\n",
        "\n",
        "\n",
        "   #Pretrained model params\n",
        "\n",
        "    # print('Encoder Model: {0}, Decoder Model : {1}'.format(model_encoder, model_decoder))\n",
        "    # print('GAN Model Generator:{0} & Discriminator : {1} '.format(model_generator, model_discriminator))\n",
        "\n",
        "\n",
        "    network_data_Enc = encoder_state_dict\n",
        "    network_data_Dec = decoder_state_dict\n",
        "\n",
        "    network_data_G = gen_state_dict\n",
        "\n",
        "    network_data_D = disc_state_dict\n",
        "\n",
        "    model_encoder = Encoder(num_points=2048, latent_dim=256)\n",
        "    model_encoder.load_state_dict(network_data_Enc)\n",
        "\n",
        "    model_decoder = Decoder()\n",
        "    model_decoder.load_state_dict(network_data_Dec)\n",
        "\n",
        "    model_G = Generator()\n",
        "    model_G.load_state_dict(network_data_G)\n",
        "\n",
        "    model_D = Discriminator()\n",
        "    model_D.load_state_dict(network_data_D)\n",
        "\n",
        "\n",
        "\n",
        "    # params = get_n_params(model_encoder)\n",
        "    # print('| Number of Encoder parameters [' + str(params) + ']...')\n",
        "\n",
        "    # params = get_n_params(model_decoder)\n",
        "    # print('| Number of Decoder parameters [' + str(params) + ']...')\n",
        "\n",
        "\n",
        "\n",
        "    chamfer = ChamferLoss({})\n",
        "    nll = NLL()\n",
        "    mse = MSE(reduction = 'elementwise_mean')\n",
        "    norm = Norm(dims=z_dim)\n",
        "\n",
        "    epoch = 0\n",
        "\n",
        "\n",
        "    test_loss = trainRL(train_loader, valid_loader,test_loader, model_encoder, model_decoder, model_G,model_D, epoch, chamfer,nll, mse, norm)\n",
        "    print('Average Loss :{}'.format(test_loss))\n",
        "\n",
        "\n",
        "def trainRL(train_loader,valid_loader,test_loader,model_encoder,model_decoder, model_G,model_D,epoch, chamfer,nll, mse,norm):\n",
        "\n",
        "    model_encoder.eval()\n",
        "    model_decoder.eval()\n",
        "    model_G.eval()\n",
        "    model_D.eval()\n",
        "\n",
        "    epoch_size = 30\n",
        "    save_models = True\n",
        "    policy_name = \"ddpg\"\n",
        "    env_name = \"RLGAN\"\n",
        "\n",
        "\n",
        "    file_name = \"%s_%s\" % (policy_name, env_name)\n",
        "\n",
        "    if save_models and not os.path.exists(\"./pytorch_models\"):\n",
        "        os.makedirs(\"./pytorch_models\")\n",
        "\n",
        "    env = envs(model_G, model_D, model_encoder, model_decoder, epoch_size)\n",
        "\n",
        "    state_dim = 256\n",
        "    action_dim = 1\n",
        "    max_action = 10\n",
        "    # gpu_id = 1\n",
        "    device = torch.device(\"cpu\")#torch.device(\n",
        "        # \"cuda:%d\" % (gpu_id) if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    # Initialize policy\n",
        "\n",
        "    policy = DDPG(state_dim, action_dim, max_action, device)\n",
        "\n",
        "    replay_buffer = ReplayBuffer()\n",
        "\n",
        "    evaluations = [evaluate_policy(policy,valid_loader,env)]\n",
        "\n",
        "\n",
        "\n",
        "    total_timesteps = 0\n",
        "    timesteps_since_eval = 0\n",
        "    episode_num = 0\n",
        "    max_episodes_steps = 5\n",
        "    episode_reward = 0\n",
        "    episode_timesteps = 0\n",
        "    done = True\n",
        "    env.reset(epoch_size=30)\n",
        "\n",
        "    max_timesteps = 1000\n",
        "\n",
        "\n",
        "    while total_timesteps < max_timesteps:\n",
        "\n",
        "\n",
        "        if done:\n",
        "\n",
        "            try:\n",
        "                input = next(dataloader_iterator)\n",
        "            except:\n",
        "                dataloader_iterator = iter(train_loader)\n",
        "                input = next(dataloader_iterator)\n",
        "\n",
        "            # num_elements = sum(1 for _ in dataloader_iterator)\n",
        "            print(\"input shape, \")\n",
        "            if total_timesteps != 0:\n",
        "                batch_size = input.shape[0]\n",
        "                discount = 0.99\n",
        "                tau = 0.005\n",
        "                print(\"------------training--------------\")\n",
        "                # print(\"Total T: %d Episode Num: %d Episode T: %d Reward: %f\") % (total_timesteps, episode_num, episode_timesteps, episode_reward)\n",
        "                policy.train(replay_buffer, episode_timesteps, batch_size, discount, tau)\n",
        "\n",
        "            eval_freq = 300\n",
        "            # Evaluate episode\n",
        "            if timesteps_since_eval >= eval_freq:\n",
        "                timesteps_since_eval %= eval_freq\n",
        "\n",
        "                evaluations.append(evaluate_policy(policy,valid_loader,env,render = False))\n",
        "\n",
        "                if save_models: policy.save(file_name, directory=\"./pytorch_models\")\n",
        "\n",
        "                env.reset(epoch_size=30)\n",
        "                print(\"------------testing policy-----------\")\n",
        "                test_policy(policy, test_loader, env, render=True)\n",
        "\n",
        "                env.reset(epoch_size=30)\n",
        "\n",
        "\n",
        "            # Reset environment\n",
        "           # obs = env.reset()\n",
        "            done = False\n",
        "            episode_reward = 0\n",
        "            episode_timesteps = 0\n",
        "            episode_num += 1\n",
        "\n",
        "        # Select action randomly or according to policy\n",
        "        obs = env.agent_input(input)\n",
        "        start_timesteps = 100\n",
        "        expl_noise = 0.1\n",
        "        max_action = 1\n",
        "        batch_size = input.shape[0]\n",
        "        z_dim = 1\n",
        "\n",
        "        if total_timesteps < start_timesteps:\n",
        "          #  action_t = torch.rand(args.batch_size, args.z_dim) # TODO checked rand instead of randn\n",
        "            action_t = torch.FloatTensor(batch_size, z_dim).uniform_(-max_action, max_action)\n",
        "            action = action_t.detach().numpy()#.squeeze(0)\n",
        "        else:\n",
        "\n",
        "            action = policy.select_action(np.array(obs))\n",
        "            if expl_noise != 0:\n",
        "                action = (action + np.random.normal(0, expl_noise, size=z_dim)).clip(-max_action * np.ones(z_dim,), max_action * np.ones(z_dim,))\n",
        "\n",
        "        #      Convert each element of action to a list containing a single element\n",
        "            action = np.array([[np.float32(a)] for a in action])\n",
        "            action_t = torch.tensor(action).unsqueeze(dim=0)\n",
        "        # Perform action\n",
        "\n",
        "        new_obs, _, reward, done = env(input, action_t,disp = True)\n",
        "\n",
        "       # new_obs, reward, done, _ = env.step(action)\n",
        "        done_bool = 0 if episode_timesteps + 1 == max_episodes_steps else float(done)\n",
        "        episode_reward += reward\n",
        "\n",
        "        # Store data in replay buffer\n",
        "        replay_buffer.add((obs, new_obs, action, reward, done_bool))\n",
        "\n",
        "        obs = new_obs\n",
        "\n",
        "        episode_timesteps += 1\n",
        "        total_timesteps += 1\n",
        "        timesteps_since_eval += 1\n",
        "        print(\"epsiode_timesteps: \",episode_timesteps)\n",
        "        print(\"total_timesteps: \",total_timesteps)\n",
        "\n",
        "class envs(nn.Module):\n",
        "    def __init__(self,model_G,model_D,model_encoder,model_decoder,epoch_size):\n",
        "        super(envs,self).__init__()\n",
        "\n",
        "        self.nll = NLL()\n",
        "        self.mse = MSE(reduction='elementwise_mean')\n",
        "        z_dim = 1\n",
        "        self.norm = Norm(dims=z_dim)\n",
        "        self.chamfer = ChamferLoss({})\n",
        "        self.epoch = 0\n",
        "        self.epoch_size =epoch_size\n",
        "\n",
        "        self.model_G = model_G\n",
        "        self.model_D = model_D\n",
        "        self.model_encoder = model_encoder\n",
        "        self.model_decoder = model_decoder\n",
        "        self.j = 1\n",
        "        self.figures = 3\n",
        "        self.attempts = 5\n",
        "        self.end = time.time()\n",
        "        self.batch_time = AverageMeter()\n",
        "        self.state_dim = 128\n",
        "        self.attempt_id =0\n",
        "        self.state_prev = np.zeros([4,])\n",
        "        self.iter = 0\n",
        "    def reset(self,epoch_size, figures =3):\n",
        "        self.j = 1;\n",
        "        self.i = 0;\n",
        "        self.figures = figures;\n",
        "        self.epoch_size= epoch_size\n",
        "        # print(\"epoch_size: \",self.epoch_size)\n",
        "        # self.batch_size = batch_size\n",
        "    def agent_input(self,input):\n",
        "        with torch.no_grad():\n",
        "            input = input\n",
        "            # input_var = Variable(input, requires_grad=True)\n",
        "            input = input.transpose(1,2)\n",
        "            print(\"input shape: \",input.shape)\n",
        "            if input.size(-1) == 1024:\n",
        "                # Define the desired output size for upsampling\n",
        "                desired_size = 2048\n",
        "\n",
        "                # Calculate the scale factor for upsampling\n",
        "                scale_factor = desired_size / input.size(-1)\n",
        "\n",
        "                # Upsample the input tensor using bilinear interpolation\n",
        "                input_upsampled = F.interpolate(input.float(), scale_factor=scale_factor, mode='nearest-exact')\n",
        "\n",
        "                # Pass the upsampled input to the encoder\n",
        "                encoder_out_mean, encoder_out_logvar = self.model_encoder(input_upsampled)\n",
        "            else:\n",
        "                # If input size does not match, directly pass the input to the encoder\n",
        "                encoder_out_mean, encoder_out_logvar = self.model_encoder(input.float())\n",
        "\n",
        "            # Reparameterization trick\n",
        "            epsilon = torch.randn_like(encoder_out_logvar)\n",
        "            encoder_out = encoder_out_mean + torch.exp(0.5 * encoder_out_logvar) * epsilon\n",
        "            out = encoder_out.detach().numpy().squeeze()\n",
        "        return out\n",
        "    def forward(self,input,action,render=False, disp=False):\n",
        "        state_dim = 256\n",
        "        with torch.no_grad():\n",
        "            # Encoder Input\n",
        "            input = input\n",
        "            # input_var = Variable(input, requires_grad=True)\n",
        "\n",
        "            # Encoder  output\n",
        "            input = input.transpose(1,2)\n",
        "            if input.size(-1) == 1024:\n",
        "              input = F.interpolate(input.float(), scale_factor=2, mode='nearest-exact')\n",
        "\n",
        "            # for VAE\n",
        "            encoder_out_mean, encoder_out_logvar = self.model_encoder(input.float())\n",
        "            # Reparameterization trick\n",
        "            epsilon = torch.randn_like(encoder_out_logvar)\n",
        "            encoder_out = encoder_out_mean + torch.exp(0.5 * encoder_out_logvar) * epsilon\n",
        "            # print(\"encoder_out shape: \",encoder_out.shape)\n",
        "\n",
        "            # D Decoder Output\n",
        "            pc_1 = self.model_decoder(encoder_out)\n",
        "            # Generator Input\n",
        "            # z = Variable(action, requires_grad=True)#.cuda()\n",
        "            z = action\n",
        "            z = z.view(-1,1)\n",
        "\n",
        "            # Generator Output\n",
        "            # print(  \"z shape: \",z.shape)\n",
        "            out_GD = self.model_G(z)\n",
        "            # print(\"----out_GD shape \",out_GD.shape)\n",
        "            out_G = torch.squeeze(out_GD, dim=1)\n",
        "            num_samples = encoder_out.shape[0]\n",
        "            out_G = out_G[:num_samples]\n",
        "            out_G = out_G.contiguous().view(-1, state_dim)\n",
        "\n",
        "            # Discriminator Output\n",
        "            out_D = self.model_D(out_GD) # TODO Alert major mistake\n",
        "\n",
        "            # H Decoder Output\n",
        "            pc_1_G = self.model_decoder(out_G)\n",
        "\n",
        "\n",
        "            # Preprocesing of Input PC and Predicted PC for Visdom\n",
        "            # print(\"input-------- \",input.shape)\n",
        "            trans_input = torch.squeeze(input, dim=1)\n",
        "            trans_input = torch.transpose(trans_input, 1, 2)\n",
        "            trans_input_temp = trans_input[0, :, :]\n",
        "            pc_1_temp = pc_1[0, :, :] # D Decoder PC\n",
        "            pc_1_G_temp = pc_1_G[0, :, :] # H Decoder PC\n",
        "\n",
        "\n",
        "        # Discriminator Loss\n",
        "        loss_D = self.nll(out_D)\n",
        "\n",
        "        # print(\"outG shape: \",out_G.shape)\n",
        "        # print(\"encoder out shape: \",encoder_out.shape)\n",
        "        # Loss Between Noisy GFV and Clean GFV\n",
        "        loss_GFV = self.mse(out_G, encoder_out)\n",
        "\n",
        "        # Norm Loss\n",
        "        loss_norm = self.norm(z)\n",
        "\n",
        "        # Chamfer loss\n",
        "        # print(\"pc1g shape \",pc_1_G.shape)\n",
        "        # print(\"pc1 shape \",pc_1.shape)\n",
        "        loss_chamfer = self.chamfer(pc_1_G, pc_1)\n",
        "\n",
        "        # States Formulation\n",
        "        state_curr = np.array([loss_D.data.numpy(), loss_GFV.data.numpy()\n",
        "                                  , loss_chamfer.data.numpy(), loss_norm.data.numpy()])\n",
        "      #  state_prev = self.state_prev\n",
        "\n",
        "        reward_D = state_curr[0]#state_curr[0] - self.state_prev[0]\n",
        "        reward_GFV =-state_curr[1]# -state_curr[1] + self.state_prev[1]\n",
        "        reward_chamfer = -state_curr[2]#-state_curr[2] + self.state_prev[2]\n",
        "        reward_norm =-state_curr[3] # - state_curr[3] + self.state_prev[3]\n",
        "        # Reward Formulation\n",
        "        reward = ( reward_D *0.01 + reward_GFV * 10.0 + reward_chamfer *100.0 + reward_norm*1/10)\n",
        "\n",
        "        # measured elapsed time\n",
        "        self.batch_time.update(time.time() - self.end)\n",
        "        self.end = time.time()\n",
        "\n",
        "        if disp:\n",
        "            print('[{4}][{0}/{1}]\\t Reward: {2}\\t States: {3}'.format(self.i, self.epoch_size,reward,state_curr,self.iter))\n",
        "            self.i += 1\n",
        "            if(self.i>=self.epoch_size):\n",
        "                self.i=0\n",
        "                self.iter +=1\n",
        "\n",
        "        done = True\n",
        "        state = out_G.detach().data.numpy().squeeze()\n",
        "        # print(\"State: \",state)\n",
        "        # print(\"Reward: \",reward)\n",
        "        # print(\"Done: \",done)\n",
        "        return state, _, reward, done\n",
        "\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "\n",
        "    main()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "APtbF1aCnQm4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "76ac3e0d-3833-42bd-e8ac-15d76e39c9f8"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train data length  1824\n",
            "test data length  783\n",
            "-----------------evaluating---------------\n",
            "input shape:  torch.Size([1, 3, 1024])\n",
            "[0][0/30]\t Reward: -21.445465255379677\t States: [-0.18434232  1.0996633   0.1036447   0.8251937 ]\n",
            "input shape:  torch.Size([1, 3, 1024])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/_reduction.py:13: UserWarning: reduction='elementwise_mean' is deprecated, please use reduction='mean' instead.\n",
            "  warnings.warn(\"reduction='elementwise_mean' is deprecated, please use reduction='mean' instead.\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "total_timesteps:  189\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[6][9/30]\t Reward: -26.854869256317613\t States: [-0.18435219  1.0562485   0.1006818  62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  190\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[6][10/30]\t Reward: -26.913750002682207\t States: [-0.18435219  1.0558008   0.10131538 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  191\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[6][11/30]\t Reward: -26.854184398949144\t States: [-0.18435219  1.0507718   0.10122262 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  192\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[6][12/30]\t Reward: -26.965932379066942\t States: [-0.18435219  1.0614865   0.10126863 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  193\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[6][13/30]\t Reward: -26.771341691315172\t States: [-0.18435219  1.0438594   0.10108544 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  194\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[6][14/30]\t Reward: -26.810244450867174\t States: [-0.18435219  1.0491039   0.10095002 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  195\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[6][15/30]\t Reward: -26.89894033461809\t States: [-0.18435219  1.0539421   0.10135315 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  196\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[6][16/30]\t Reward: -26.885662356913087\t States: [-0.18435219  1.0557351   0.10104107 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  197\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[6][17/30]\t Reward: -27.167821357548235\t States: [-0.18435219  1.0738184   0.10205433 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  198\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[6][18/30]\t Reward: -26.770299653112886\t States: [-0.18435219  1.0484828   0.10061268 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  199\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[6][19/30]\t Reward: -26.731615940630434\t States: [-0.18435219  1.0425975   0.10081436 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  200\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[6][20/30]\t Reward: -26.870891580879686\t States: [-0.18435219  1.0527036   0.10119651 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  201\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[6][21/30]\t Reward: -26.903478367775676\t States: [-0.18435197  1.0705243   0.10206373 59.900185  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  202\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[6][22/30]\t Reward: -26.676754614710806\t States: [-0.1843521   1.0482062   0.10073391 61.194584  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  203\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[6][23/30]\t Reward: -26.530453646332024\t States: [-0.18435182  1.0585225   0.10103997 58.393887  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  204\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[6][24/30]\t Reward: -25.682537529319525\t States: [-0.18435095  1.0547671   0.10118563 50.144592  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  205\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[6][25/30]\t Reward: -25.948138715624808\t States: [-0.18435138  1.0446078   0.10091107 54.09111   ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  206\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[6][26/30]\t Reward: -22.559064836651086\t States: [-0.18434717  1.0463005   0.10131133 19.630835  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  207\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[6][27/30]\t Reward: -23.62082103535533\t States: [-0.18434827  1.0624853   0.10198412 27.95712   ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  208\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[6][28/30]\t Reward: -22.49084342882037\t States: [-0.1843466   1.0712414   0.10197809 15.787768  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  209\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[6][29/30]\t Reward: -21.110822500288485\t States: [-0.1843442   1.0644381   0.10154784  3.0981429 ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  210\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[7][0/30]\t Reward: -20.59656225398183\t States: [-0.18434341  1.0462931   0.10033023  0.9876407 ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  211\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[7][1/30]\t Reward: -20.938918717503547\t States: [-0.18434483  1.0349736   0.10036026  5.513131  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  212\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[7][2/30]\t Reward: -20.874352968484164\t States: [-0.18434413  1.048895    0.10083523  3.0003612 ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  213\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[7][3/30]\t Reward: -20.802980895638466\t States: [-0.18434364  1.0556436   0.10090768  1.5393354 ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  214\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[7][4/30]\t Reward: -20.706195745021105\t States: [-0.18434317  1.0540879   0.10109598  0.5387535 ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  215\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[7][5/30]\t Reward: -20.61082582809031\t States: [-0.18434256  1.0508649   0.10094419  0.05913932]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  216\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[7][6/30]\t Reward: -20.848702998459338\t States: [-0.18433943  1.0602225   0.10125173  1.1946166 ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  217\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[7][7/30]\t Reward: -20.572579738944768\t States: [-0.18433963  1.0401418   0.10076939  0.92379564]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  218\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[7][8/30]\t Reward: -21.259494181871414\t States: [-0.18433774  1.0466274   0.10099149  6.9222803 ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  219\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[7][9/30]\t Reward: -21.310696372538803\t States: [-0.18433781  1.0537057   0.10111903  6.598934  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  220\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[7][10/30]\t Reward: -22.310635140538214\t States: [-0.184336   1.0486982  0.1004054 17.812704 ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  221\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[7][11/30]\t Reward: -22.445762245357038\t States: [-0.18433616  1.0569288   0.10177253 16.973782  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  222\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[7][12/30]\t Reward: -21.702722443342207\t States: [-0.18433642  1.0271153   0.09988035 14.416911  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  223\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[7][13/30]\t Reward: -25.092656839936975\t States: [-0.18433343  1.0411665   0.10083009 45.961388  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  224\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[7][14/30]\t Reward: -25.398656441271303\t States: [-0.18433347  1.0629473   0.10163534 46.038067  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  225\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[7][15/30]\t Reward: -25.839905973374844\t States: [-0.18433294  1.0385988   0.10073945 53.7813    ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  226\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[7][16/30]\t Reward: -26.639020106345413\t States: [-0.18433245  1.0408125   0.10041703 61.873493  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  227\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[7][17/30]\t Reward: -26.842225125879047\t States: [-0.18433248  1.0608708   0.10107122 61.245518  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  228\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[7][18/30]\t Reward: -26.90050803691149\t States: [-0.1843324   1.0541422   0.10134882 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  229\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[7][19/30]\t Reward: -26.764514675438406\t States: [-0.1843324   1.0426663   0.10113648 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  230\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[7][20/30]\t Reward: -26.914031287729742\t States: [-0.1843324   1.0596111   0.10093717 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  231\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[7][21/30]\t Reward: -27.177853366434576\t States: [-0.1843324   1.0762259   0.10191391 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  232\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[7][22/30]\t Reward: -26.79835342437029\t States: [-0.1843324   1.0469514   0.10104635 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  233\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[7][23/30]\t Reward: -27.224611869156362\t States: [-0.1843324   1.0767483   0.10232925 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  234\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[7][24/30]\t Reward: -27.114053001701834\t States: [-0.1843324   1.072       0.10169849 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  235\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[7][25/30]\t Reward: -26.90512173444033\t States: [-0.1843324   1.0558069   0.10122849 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  236\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[7][26/30]\t Reward: -27.0217134860158\t States: [-0.1843324   1.0654733   0.10142776 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  237\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[7][27/30]\t Reward: -26.77073382407427\t States: [-0.1843324   1.0452057   0.10094473 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  238\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[7][28/30]\t Reward: -27.042205264866354\t States: [-0.1843324   1.0648685   0.10169317 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  239\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[7][29/30]\t Reward: -26.921357145607473\t States: [-0.1843324   1.0571561   0.10125592 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  240\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[8][0/30]\t Reward: -26.804965069592\t States: [-0.1843324  1.0492551  0.1008821 62.223606 ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  241\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[8][1/30]\t Reward: -27.00256966620684\t States: [-0.1843324   1.0625743   0.10152623 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  242\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[8][2/30]\t Reward: -26.95663892298937\t States: [-0.1843324   1.0559156   0.10173279 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  243\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[8][3/30]\t Reward: -26.85613297492266\t States: [-0.1843324   1.0541658   0.10090271 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  244\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[8][4/30]\t Reward: -26.83315121203661\t States: [-0.1843324   1.0503206   0.10105741 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  245\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[8][5/30]\t Reward: -26.635716786682607\t States: [-0.1843324   1.0395709   0.10015804 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  246\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[8][6/30]\t Reward: -26.850584974586965\t States: [-0.1843324   1.054042    0.10085961 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  247\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[8][7/30]\t Reward: -26.89192556411028\t States: [-0.1843324   1.0560184   0.10107538 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  248\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[8][8/30]\t Reward: -26.799326172173025\t States: [-0.1843324   1.0481764   0.10093358 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  249\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[8][9/30]\t Reward: -26.912351777851583\t States: [-0.1843324   1.056363    0.10124518 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  250\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[8][10/30]\t Reward: -26.932947268784048\t States: [-0.1843324   1.0570381   0.10138363 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  251\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[8][11/30]\t Reward: -27.097190251648428\t States: [-0.1843324   1.0690194   0.10182792 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  252\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[8][12/30]\t Reward: -26.80441760092974\t States: [-0.1843324   1.0492053   0.10088161 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  253\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[8][13/30]\t Reward: -26.921527912914755\t States: [-0.1843324   1.055457    0.10142754 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  254\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[8][14/30]\t Reward: -26.96426831752062\t States: [-0.1843324   1.060476    0.10135305 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  255\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[8][15/30]\t Reward: -26.858305117189886\t States: [-0.1843324   1.0552076   0.10082025 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  256\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[8][16/30]\t Reward: -26.80624418526888\t States: [-0.1843324   1.0507784   0.10074256 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  257\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[8][17/30]\t Reward: -27.058388819992544\t States: [-0.1843324   1.068355    0.10150635 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  258\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[8][18/30]\t Reward: -26.789868703186514\t States: [-0.1843324   1.0488981   0.10076684 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  259\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[8][19/30]\t Reward: -27.16215901643038\t States: [-0.1843324   1.0734929   0.10203026 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  260\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[8][20/30]\t Reward: -26.808807483017446\t States: [-0.1843324   1.0479655   0.10104948 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  261\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[8][21/30]\t Reward: -26.979765674173834\t States: [-0.1843324   1.0611831   0.10143731 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  262\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[8][22/30]\t Reward: -27.043912043869497\t States: [-0.1843324   1.0664489   0.10155219 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  263\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[8][23/30]\t Reward: -26.91715978652239\t States: [-0.1843324  1.0541966  0.1015099 62.223606 ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  264\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[8][24/30]\t Reward: -26.835482051670553\t States: [-0.1843324   1.0527053   0.10084225 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  265\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[8][25/30]\t Reward: -26.65806942254305\t States: [-0.1843324  1.0399336  0.1003453 62.223606 ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  266\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[8][26/30]\t Reward: -26.886768123209478\t States: [-0.1843324   1.0583743   0.10078821 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  267\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[8][27/30]\t Reward: -26.936004838049413\t States: [-0.1843324   1.0561199   0.10150602 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  268\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[8][28/30]\t Reward: -27.016679873764517\t States: [-0.1843324   1.064081    0.10151666 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  269\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[8][29/30]\t Reward: -26.91728421121836\t States: [-0.1843324   1.0575476   0.10117605 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  270\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[9][0/30]\t Reward: -26.584894588291647\t States: [-0.1843324   1.0339175   0.10021515 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  271\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[9][1/30]\t Reward: -26.640144219696523\t States: [-0.1843324   1.0403981   0.10011959 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  272\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[9][2/30]\t Reward: -26.885624161064626\t States: [-0.1843324   1.0562137   0.10099283 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  273\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[9][3/30]\t Reward: -26.82906695276499\t States: [-0.1843324   1.0522032   0.10082831 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  274\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[9][4/30]\t Reward: -26.79321311980486\t States: [-0.1843324  1.0434619  0.1013439 62.223606 ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  275\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[9][5/30]\t Reward: -26.692155828773977\t States: [-0.1843324   1.042403    0.10043922 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  276\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[9][6/30]\t Reward: -27.107395460903646\t States: [-0.1843324   1.0649296   0.10233895 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  277\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[9][7/30]\t Reward: -26.996434560120107\t States: [-0.1843324   1.0587996   0.10184234 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  278\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[9][8/30]\t Reward: -26.827508440315725\t States: [-0.1843324   1.0493889   0.10109416 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  279\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[9][9/30]\t Reward: -26.818133225739004\t States: [-0.1843324   1.0518271   0.10075659 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  280\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[9][10/30]\t Reward: -26.91186421185732\t States: [-0.1843324   1.0581423   0.10106237 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  281\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[9][11/30]\t Reward: -26.744610300362112\t States: [-0.1843324   1.0446032   0.10074374 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  282\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[9][12/30]\t Reward: -26.982766619026663\t States: [-0.1843324   1.0660204   0.10098359 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  283\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[9][13/30]\t Reward: -26.734313896000387\t States: [-0.1843324   1.0436536   0.10073574 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  284\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[9][14/30]\t Reward: -26.75105043321848\t States: [-0.1843324   1.0432655   0.10094192 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  285\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[9][15/30]\t Reward: -26.93267845183611\t States: [-0.1843324   1.0534018   0.10174456 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  286\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[9][16/30]\t Reward: -27.011435112059118\t States: [-0.1843324   1.0639309   0.10147922 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  287\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[9][17/30]\t Reward: -26.954260399639608\t States: [-0.1843324   1.0580895   0.10149162 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  288\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[9][18/30]\t Reward: -26.911504795849325\t States: [-0.1843324   1.05728     0.10114501 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  289\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[9][19/30]\t Reward: -26.993688574135305\t States: [-0.1843324   1.062352    0.10145965 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  290\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[9][20/30]\t Reward: -26.855916014015676\t States: [-0.1843324   1.0535129   0.10096583 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  291\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[9][21/30]\t Reward: -26.707889368832113\t States: [-0.1843324   1.0438641   0.10045044 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  292\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[9][22/30]\t Reward: -26.909065475761892\t States: [-0.1843324   1.0546877   0.10137984 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  293\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[9][23/30]\t Reward: -27.07400166064501\t States: [-0.1843324  1.0657648  0.1019215 62.223606 ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  294\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[9][24/30]\t Reward: -26.721844008266928\t States: [-0.1843324   1.0440526   0.10057114 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  295\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[9][25/30]\t Reward: -26.641618838608267\t States: [-0.1843324   1.04048     0.10012615 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  296\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[9][26/30]\t Reward: -26.971841385662557\t States: [-0.1843324   1.0587151   0.10160486 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  297\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[9][27/30]\t Reward: -26.828784426748754\t States: [-0.1843324   1.0505322   0.10099258 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  298\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[9][28/30]\t Reward: -26.882961323559286\t States: [-0.1843324  1.0561297  0.1009746 62.223606 ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  299\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[9][29/30]\t Reward: -26.86041169434786\t States: [-0.1843324   1.0553845   0.10082363 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  300\n",
            "input shape, \n",
            "------------training--------------\n",
            "-----------------evaluating---------------\n",
            "input shape:  torch.Size([1, 3, 1024])\n",
            "[10][0/30]\t Reward: -26.052625596374273\t States: [-0.18449841  0.8874297   0.09093589 80.82894   ]\n",
            "input shape:  torch.Size([1, 3, 1024])\n",
            "[10][1/30]\t Reward: -28.816810212135316\t States: [-0.1844964   1.0467608   0.10336459 80.108986  ]\n",
            "input shape:  torch.Size([1, 3, 1024])\n",
            "[10][2/30]\t Reward: -26.342211574167013\t States: [-0.18449722  0.93043464  0.08995935 80.40085   ]\n",
            "input shape:  torch.Size([1, 3, 1024])\n",
            "[10][3/30]\t Reward: -28.4204766446352\t States: [-0.18449718  1.0555133   0.09825024 80.38475   ]\n",
            "input shape:  torch.Size([1, 3, 1024])\n",
            "[10][4/30]\t Reward: -29.11638843685388\t States: [-0.1844975   1.0716735   0.10348436 80.49372   ]\n",
            "input shape:  torch.Size([1, 3, 1024])\n",
            "[10][5/30]\t Reward: -26.728783283233643\t States: [-0.1844976   0.91008985  0.09574862 80.51178   ]\n",
            "---------------------------------------\n",
            "Evaluation over 6 episodes: -27.579549\n",
            "---------------------------------------\n",
            "------------testing policy-----------\n",
            "input shape:  torch.Size([1, 3, 1024])\n",
            "[10][0/30]\t Reward: -30.03324976488948\t States: [-0.18449716  1.1468773   0.10527392 80.3524    ]\n",
            "input shape:  torch.Size([1, 3, 1024])\n",
            "[10][1/30]\t Reward: -28.334528194069865\t States: [-0.18449706  1.0646397   0.09654578 80.317085  ]\n",
            "input shape:  torch.Size([1, 3, 1024])\n",
            "[10][2/30]\t Reward: -26.784161983132364\t States: [-0.18449646  0.8978466   0.09793031 80.1082    ]\n",
            "input shape:  torch.Size([1, 3, 1024])\n",
            "[10][3/30]\t Reward: -28.149259901344777\t States: [-0.1844931   1.0478588   0.09781188 78.87639   ]\n",
            "input shape:  torch.Size([1, 3, 1024])\n",
            "[10][4/30]\t Reward: -30.148231308162213\t States: [-0.18449828  1.1694888   0.10377406 80.74093   ]\n",
            "input shape:  torch.Size([1, 3, 1024])\n",
            "[10][5/30]\t Reward: -28.097529488205907\t States: [-0.18449837  1.0295781   0.09718302 80.81602   ]\n",
            "input shape:  torch.Size([1, 3, 1024])\n",
            "[10][6/30]\t Reward: -27.702568511217834\t States: [-0.18449764  0.98823285  0.09762359 80.560356  ]\n",
            "input shape:  torch.Size([1, 3, 1024])\n",
            "[10][7/30]\t Reward: -28.77170033842325\t States: [-0.18449584  1.0802352   0.09978184 79.89319   ]\n",
            "input shape:  torch.Size([1, 3, 1024])\n",
            "[10][8/30]\t Reward: -29.615139328241348\t States: [-0.18449831  1.1161479   0.10375858 80.759575  ]\n",
            "input shape:  torch.Size([1, 3, 1024])\n",
            "[10][9/30]\t Reward: -27.58770655632019\t States: [-0.18449807  0.9744712   0.09770475 80.70674   ]\n",
            "input shape:  torch.Size([1, 3, 1024])\n",
            "[10][10/30]\t Reward: -30.04679473116994\t States: [-0.1844985   1.1544821   0.10414842 80.85287   ]\n",
            "input shape:  torch.Size([1, 3, 1024])\n",
            "[10][11/30]\t Reward: -29.53637440025806\t States: [-0.18449765  1.1070032   0.10411552 80.52946   ]\n",
            "---------------------------------------\n",
            "Evaluation over 12 episodes: -28.733937\n",
            "---------------------------------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[10][0/30]\t Reward: -26.923816433250906\t States: [-0.1843324   1.0586519   0.10113093 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  301\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[10][1/30]\t Reward: -26.956078043282034\t States: [-0.1843324   1.0579346   0.10152528 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  302\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[10][2/30]\t Reward: -26.8839825001359\t States: [-0.1843324   1.054179    0.10117989 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  303\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[10][3/30]\t Reward: -26.80786841183901\t States: [-0.1843324   1.0486362   0.10097302 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  304\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[10][4/30]\t Reward: -26.82944439917803\t States: [-0.1843324   1.0495485   0.10109755 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  305\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[10][5/30]\t Reward: -26.7903902438283\t States: [-0.1843324   1.0477173   0.10089013 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  306\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[10][6/30]\t Reward: -26.839139690697195\t States: [-0.1843324   1.0534065   0.10080871 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  307\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[10][7/30]\t Reward: -26.85785793334246\t States: [-0.1843324   1.0521622   0.10112032 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  308\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[10][8/30]\t Reward: -26.867791792452337\t States: [-0.1843324   1.0572214   0.10071374 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  309\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[10][9/30]\t Reward: -27.079728325903417\t States: [-0.1843324   1.0647595   0.10207929 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  310\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[10][10/30]\t Reward: -26.7993795183301\t States: [-0.1843324  1.0520586  0.1005459 62.223606 ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  311\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[10][11/30]\t Reward: -26.79082163244486\t States: [-0.1843324   1.0473925   0.10092693 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  312\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[10][12/30]\t Reward: -26.738523772060873\t States: [-0.1843324   1.0412949   0.10101371 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  313\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[10][13/30]\t Reward: -26.863269588053228\t States: [-0.1843324   1.0527128   0.10111938 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  314\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[10][14/30]\t Reward: -26.939680805504324\t States: [-0.1843324   1.0551201   0.10164276 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  315\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[10][15/30]\t Reward: -27.145833900272848\t States: [-0.1843324   1.0705446   0.10216184 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  316\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[10][16/30]\t Reward: -26.791494717895986\t States: [-0.1843324   1.0461866   0.10105425 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  317\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[10][17/30]\t Reward: -27.08858721524477\t States: [-0.1843324   1.0682681   0.10181703 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  318\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[10][18/30]\t Reward: -26.597790351212026\t States: [-0.1843324   1.0330472   0.10043114 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  319\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[10][19/30]\t Reward: -27.09434770613909\t States: [-0.1843324   1.0692117   0.10178027 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  320\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[10][20/30]\t Reward: -26.89650230675936\t States: [-0.1843324  1.0563579  0.1010872 62.223606 ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  321\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[10][21/30]\t Reward: -26.995170643627645\t States: [-0.1843324   1.0619069   0.10151897 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  322\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[10][22/30]\t Reward: -26.946137329638006\t States: [-0.1843324   1.0585883   0.10136051 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  323\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[10][23/30]\t Reward: -26.820079913437368\t States: [-0.1843324   1.0506401   0.10089475 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  324\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[10][24/30]\t Reward: -26.64900027781725\t States: [-0.1843324   1.0382683   0.10042113 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  325\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[10][25/30]\t Reward: -26.792037269175054\t States: [-0.1843324   1.0485847   0.10081986 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  326\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[10][26/30]\t Reward: -26.98195688992739\t States: [-0.1843324   1.05574     0.10200353 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  327\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[10][27/30]\t Reward: -26.914678743183615\t States: [-0.1843324   1.0592278   0.10098197 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  328\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[10][28/30]\t Reward: -26.89253815084696\t States: [-0.1843324   1.0544736   0.10123598 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  329\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[10][29/30]\t Reward: -26.79201700359583\t States: [-0.1843324   1.0495524   0.10072289 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  330\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[11][0/30]\t Reward: -27.032390466034414\t States: [-0.1843324   1.0669568   0.10138619 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  331\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[11][1/30]\t Reward: -26.827602913677694\t States: [-0.1843324   1.0513163   0.10090236 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  332\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[11][2/30]\t Reward: -26.551358183920385\t States: [-0.1843324   1.0313327   0.10013827 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  333\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[11][3/30]\t Reward: -26.649784078896047\t States: [-0.1843324   1.0372175   0.10053405 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  334\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[11][4/30]\t Reward: -26.727530589401724\t States: [-0.1843324   1.0445442   0.10057884 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  335\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[11][5/30]\t Reward: -27.221216788589956\t States: [-0.1843324   1.0761578   0.10235435 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  336\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[11][6/30]\t Reward: -26.828852227032186\t States: [-0.1843324   1.0496483   0.10108165 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  337\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[11][7/30]\t Reward: -26.835528096258642\t States: [-0.1843324   1.0504091   0.10107233 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  338\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[11][8/30]\t Reward: -26.8640331235528\t States: [-0.1843324   1.0530916   0.10108913 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  339\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[11][9/30]\t Reward: -26.821643790304663\t States: [-0.1843324   1.0467259   0.10130181 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  340\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[11][10/30]\t Reward: -27.057437231838705\t States: [-0.1843324   1.0657125   0.10176109 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  341\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[11][11/30]\t Reward: -27.038827469646932\t States: [-0.1843324   1.0637984   0.10176639 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  342\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[11][12/30]\t Reward: -26.84520446330309\t States: [-0.1843324   1.0552399   0.10068601 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  343\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[11][13/30]\t Reward: -27.054303219616415\t States: [-0.1843324  1.0661739  0.1016836 62.223606 ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  344\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[11][14/30]\t Reward: -27.060730984508993\t States: [-0.1843324   1.0675439   0.10161088 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  345\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[11][15/30]\t Reward: -26.85167141824961\t States: [-0.1843324   1.0516878   0.10110589 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  346\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[11][16/30]\t Reward: -26.75782345801592\t States: [-0.1843324   1.0464216   0.10069403 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  347\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[11][17/30]\t Reward: -26.79460220605135\t States: [-0.1843324   1.0500755   0.10069643 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  348\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[11][18/30]\t Reward: -26.910618623793127\t States: [-0.1843324   1.055452    0.10131895 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  349\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[11][19/30]\t Reward: -27.348863115608694\t States: [-0.1843324   1.0874052   0.10250607 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  350\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[11][20/30]\t Reward: -26.927485546171667\t States: [-0.1843324   1.0596814   0.10106467 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  351\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[11][21/30]\t Reward: -26.958862921297552\t States: [-0.1843324   1.0603138   0.10131521 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  352\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[11][22/30]\t Reward: -27.030069610178472\t States: [-0.1843324   1.0648074   0.10157792 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  353\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[11][23/30]\t Reward: -26.876754095852377\t States: [-0.1843324   1.0549958   0.10102592 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  354\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[11][24/30]\t Reward: -26.95656739741564\t States: [-0.1843324   1.0583302   0.10149062 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  355\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[11][25/30]\t Reward: -26.812167992889883\t States: [-0.1843324   1.050867    0.10079294 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  356\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[11][26/30]\t Reward: -26.823316594660284\t States: [-0.1843324   1.0479677   0.10119436 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  357\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[11][27/30]\t Reward: -26.853319933712484\t States: [-0.1843324   1.053733    0.10091786 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  358\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[11][28/30]\t Reward: -27.106642803251745\t States: [-0.1843324   1.0663313   0.10219126 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  359\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[11][29/30]\t Reward: -26.91576921015978\t States: [-0.1843324   1.0568682   0.10122883 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  360\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[12][0/30]\t Reward: -26.897287597954275\t States: [-0.1843324   1.053116    0.10141924 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  361\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[12][1/30]\t Reward: -26.911238065063955\t States: [-0.1843324   1.0585823   0.10101211 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  362\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[12][2/30]\t Reward: -26.9473329988122\t States: [-0.1843324   1.0598165   0.10124964 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  363\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[12][3/30]\t Reward: -26.882374813854696\t States: [-0.1843324  1.0561551  0.1009662 62.223606 ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  364\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[12][4/30]\t Reward: -26.928752144873144\t States: [-0.1843324   1.0540702   0.10163846 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  365\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[12][5/30]\t Reward: -26.826173296272756\t States: [-0.1843324   1.050786    0.10094109 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  366\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[12][6/30]\t Reward: -26.69982545644045\t States: [-0.1843324   1.0413378   0.10062243 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  367\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[12][7/30]\t Reward: -26.821603259146215\t States: [-0.1843324   1.0461425   0.10135975 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  368\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[12][8/30]\t Reward: -26.676924606859686\t States: [-0.1843324   1.0394096   0.10058624 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  369\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[12][9/30]\t Reward: -26.839810242950918\t States: [-0.1843324   1.0502534   0.10113072 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  370\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[12][10/30]\t Reward: -26.93098180562258\t States: [-0.1843324  1.0567847  0.1013893 62.223606 ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  371\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[12][11/30]\t Reward: -26.896103849709036\t States: [-0.1843324   1.0533522   0.10138378 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  372\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[12][12/30]\t Reward: -26.957903137505056\t States: [-0.1843324   1.0596657   0.10137042 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  373\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[12][13/30]\t Reward: -26.917101671993734\t States: [-0.1843324   1.0581704   0.10111193 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  374\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[12][14/30]\t Reward: -26.850030502378942\t States: [-0.1843324   1.0511807   0.10114019 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  375\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[12][15/30]\t Reward: -26.416129401028158\t States: [-0.1843324   1.0233791   0.09958135 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  376\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[12][16/30]\t Reward: -26.637011101543905\t States: [-0.1843324   1.0348302   0.10064505 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  377\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[12][17/30]\t Reward: -26.791795870363714\t States: [-0.1843324   1.0509027   0.10058565 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  378\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[12][18/30]\t Reward: -26.821686258614065\t States: [-0.1843324   1.0491279   0.10106203 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  379\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[12][19/30]\t Reward: -26.918851962387564\t States: [-0.1843324   1.0555016   0.10139632 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  380\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[12][20/30]\t Reward: -26.76228277951479\t States: [-0.1843324   1.0479472   0.10058607 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  381\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[12][21/30]\t Reward: -26.826901963055136\t States: [-0.1843324   1.0492649   0.10110049 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  382\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[12][22/30]\t Reward: -26.62133299380541\t States: [-0.1843324   1.037074    0.10026389 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  383\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[12][23/30]\t Reward: -26.68951951533556\t States: [-0.1843324   1.0408939   0.10056376 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  384\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[12][24/30]\t Reward: -27.04477467209101\t States: [-0.1843324   1.0680336   0.10140235 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  385\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[12][25/30]\t Reward: -26.786937793791296\t States: [-0.1843324   1.0467395   0.10095339 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  386\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[12][26/30]\t Reward: -26.891604444086553\t States: [-0.1843324   1.0547345   0.10120056 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  387\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[12][27/30]\t Reward: -26.976337960064413\t States: [-0.1843324   1.0624561   0.10127573 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  388\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[12][28/30]\t Reward: -27.098798086941244\t States: [-0.1843324   1.0681391   0.10193203 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  389\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[12][29/30]\t Reward: -26.728357603847982\t States: [-0.1843324   1.0445937   0.10058217 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  390\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[13][0/30]\t Reward: -27.113910248577596\t States: [-0.1843324   1.0684582   0.10205124 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  391\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[13][1/30]\t Reward: -26.766015669405462\t States: [-0.1843324  1.0454822  0.1008699 62.223606 ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  392\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[13][2/30]\t Reward: -26.804711600840093\t States: [-0.1843324   1.0500137   0.10080371 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  393\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[13][3/30]\t Reward: -27.00879015594721\t States: [-0.1843324   1.0623019   0.10161567 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  394\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[13][4/30]\t Reward: -27.155587008297445\t States: [-0.1843324   1.0714201   0.10217182 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  395\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[13][5/30]\t Reward: -26.736432245075704\t States: [-0.1843324   1.0434971   0.10077257 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  396\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[13][6/30]\t Reward: -26.972517600357534\t States: [-0.1843324   1.0579612   0.10168701 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  397\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[13][7/30]\t Reward: -26.88462056785822\t States: [-0.1843324   1.0509679   0.10150737 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  398\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[13][8/30]\t Reward: -27.00677536994219\t States: [-0.1843324  1.0640671  0.101419  62.223606 ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  399\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[13][9/30]\t Reward: -26.64017238289118\t States: [-0.1843324   1.0355854   0.10060114 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  400\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[13][10/30]\t Reward: -26.850792398750784\t States: [-0.1843324   1.05017     0.10124889 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  401\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[13][11/30]\t Reward: -26.808630755245687\t States: [-0.1843324   1.0484552   0.10099874 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  402\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[13][12/30]\t Reward: -26.810307135879995\t States: [-0.1843324   1.0504782   0.10081321 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  403\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[13][13/30]\t Reward: -26.761089643538\t States: [-0.1843324   1.0478579   0.10058307 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  404\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[13][14/30]\t Reward: -26.71702124744654\t States: [-0.1843324   1.0423479   0.10069338 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  405\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[13][15/30]\t Reward: -27.15913199454546\t States: [-0.1843324   1.0725877   0.10209051 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  406\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[13][16/30]\t Reward: -26.776958933174612\t States: [-0.1843324   1.0427568   0.10125187 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  407\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[13][17/30]\t Reward: -26.960572233498098\t States: [-0.1843324   1.0612814   0.10123554 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  408\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[13][18/30]\t Reward: -26.98267274171114\t States: [-0.1843324   1.0603305   0.10155164 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  409\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[13][19/30]\t Reward: -27.032758077681066\t States: [-0.1843324   1.0644062   0.10164493 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  410\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[13][20/30]\t Reward: -26.903790762722494\t States: [-0.1843324   1.0549469   0.10130118 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  411\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[13][21/30]\t Reward: -26.873590132296087\t States: [-0.1843324   1.0530418   0.10118968 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  412\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[13][22/30]\t Reward: -26.953728428184988\t States: [-0.1843324   1.0591516   0.10138008 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  413\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[13][23/30]\t Reward: -26.7204082813859\t States: [-0.1843324   1.04664     0.10029804 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  414\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[13][24/30]\t Reward: -26.84051924020052\t States: [-0.1843324   1.0509294   0.10107021 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  415\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[13][25/30]\t Reward: -27.119643023312094\t States: [-0.1843324   1.0702242   0.10193197 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  416\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[13][26/30]\t Reward: -26.75432108908892\t States: [-0.1843324   1.0454831   0.10075286 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  417\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[13][27/30]\t Reward: -26.773562958538534\t States: [-0.1843324   1.0477201   0.10072158 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  418\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[13][28/30]\t Reward: -26.785429498255255\t States: [-0.1843324   1.0494677   0.10066549 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  419\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[13][29/30]\t Reward: -26.923126807510855\t States: [-0.1843324   1.0572106   0.10126817 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  420\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[14][0/30]\t Reward: -27.13016085892916\t States: [-0.1843324   1.07226     0.10183357 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  421\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[14][1/30]\t Reward: -26.81084566384554\t States: [-0.1843324   1.0477719   0.10108922 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  422\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[14][2/30]\t Reward: -26.865104964077474\t States: [-0.1843324   1.0548966   0.10091935 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  423\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[14][3/30]\t Reward: -26.586774816811086\t States: [-0.1843324   1.0337245   0.10025325 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  424\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[14][4/30]\t Reward: -27.266041567623617\t States: [-0.1843324   1.0779749   0.10262088 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  425\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[14][5/30]\t Reward: -27.04063289433718\t States: [-0.1843324   1.064865    0.10167779 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  426\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[14][6/30]\t Reward: -27.042504182159902\t States: [-0.1843324   1.0673274   0.10145026 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  427\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[14][7/30]\t Reward: -26.745367577373983\t States: [-0.1843324   1.0438145   0.10083018 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  428\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[14][8/30]\t Reward: -26.906533768475057\t States: [-0.1843324   1.0565629   0.10116701 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  429\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[14][9/30]\t Reward: -26.958236029446127\t States: [-0.1843324   1.0598508   0.10135524 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  430\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[14][10/30]\t Reward: -26.921597352325918\t States: [-0.1843324   1.0551121   0.10146272 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  431\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[14][11/30]\t Reward: -26.85048066645861\t States: [-0.1843324   1.0521102   0.10105175 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  432\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[14][12/30]\t Reward: -26.944072624742986\t States: [-0.1843324   1.0583442   0.10136426 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  433\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[14][13/30]\t Reward: -26.921858718693258\t States: [-0.1843324   1.0576206   0.10121448 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  434\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[14][14/30]\t Reward: -26.825298300087454\t States: [-0.1843324   1.048036    0.10120735 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  435\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[14][15/30]\t Reward: -27.0612303224206\t States: [-0.1843324   1.066864    0.10168386 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  436\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[14][16/30]\t Reward: -26.897945633232595\t States: [-0.1843324   1.0540979   0.10132763 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  437\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[14][17/30]\t Reward: -26.885193517506124\t States: [-0.1843324   1.0561398   0.10099591 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  438\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[14][18/30]\t Reward: -27.086179038584234\t States: [-0.1843324  1.0663486  0.1019849 62.223606 ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  439\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[14][19/30]\t Reward: -26.88608728915453\t States: [-0.1843324   1.0516517   0.10145366 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  440\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[14][20/30]\t Reward: -27.108006557524206\t States: [-0.1843324   1.0681568   0.10202234 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  441\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[14][21/30]\t Reward: -27.132391860783102\t States: [-0.1843324   1.0755811   0.10152377 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  442\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[14][22/30]\t Reward: -26.962924977838995\t States: [-0.1843324   1.0594436   0.10144285 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  443\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[14][23/30]\t Reward: -26.69392549067736\t States: [-0.1843324   1.0431399   0.10038322 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  444\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[14][24/30]\t Reward: -26.949935188591482\t States: [-0.1843324   1.0634209   0.10091522 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  445\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[14][25/30]\t Reward: -26.78302221566439\t States: [-0.1843324  1.0496519  0.100623  62.223606 ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  446\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[14][26/30]\t Reward: -26.67279996544123\t States: [-0.1843324  1.0407156  0.1004144 62.223606 ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  447\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[14][27/30]\t Reward: -26.935712626278402\t States: [-0.1843324  1.0589229  0.1012228 62.223606 ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  448\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[14][28/30]\t Reward: -26.975415876209738\t States: [-0.1843324   1.0619118   0.10132094 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  449\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[14][29/30]\t Reward: -26.999768396914007\t States: [-0.1843324   1.0606755   0.10168809 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  450\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[15][0/30]\t Reward: -26.750795474350454\t States: [-0.1843324   1.0444245   0.10082346 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  451\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[15][1/30]\t Reward: -26.769664367735388\t States: [-0.1843324  1.045722   0.1008824 62.223606 ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  452\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[15][2/30]\t Reward: -26.81016080647707\t States: [-0.1843324   1.0553242   0.10032715 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  453\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[15][3/30]\t Reward: -27.161824336349966\t States: [-0.1843324   1.0739158   0.10198462 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  454\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[15][4/30]\t Reward: -26.63105331927538\t States: [-0.1843324   1.0367216   0.10039634 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  455\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[15][5/30]\t Reward: -26.951809307634832\t States: [-0.1843324   1.0572273   0.10155333 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  456\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[15][6/30]\t Reward: -26.618316402733328\t States: [-0.1843324   1.0351114   0.10042998 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  457\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[15][7/30]\t Reward: -26.994653424322607\t States: [-0.1843324   1.0614561   0.10155889 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  458\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[15][8/30]\t Reward: -26.756591430008413\t States: [-0.1843324   1.0457921   0.10074466 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  459\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[15][9/30]\t Reward: -27.034279188215734\t States: [-0.1843324   1.0636338   0.10173737 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  460\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[15][10/30]\t Reward: -26.65553354293108\t States: [-0.1843324   1.0358607   0.10072723 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  461\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[15][11/30]\t Reward: -26.932950845062734\t States: [-0.1843324   1.0600652   0.10108095 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  462\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[15][12/30]\t Reward: -26.907071551382543\t States: [-0.1843324   1.0595733   0.10087135 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  463\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[15][13/30]\t Reward: -26.834757259190084\t States: [-0.1843324   1.0516487   0.10094066 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  464\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[15][14/30]\t Reward: -26.6594293025136\t States: [-0.1843324  1.0399445  0.1003578 62.223606 ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  465\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[15][15/30]\t Reward: -26.78646542698145\t States: [-0.1843324   1.0471519   0.10090742 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  466\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[15][16/30]\t Reward: -26.551180413067343\t States: [-0.1843324   1.0321128   0.10005848 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  467\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[15][17/30]\t Reward: -27.11528562575579\t States: [-0.1843324   1.0700729   0.10190353 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  468\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[15][18/30]\t Reward: -26.921287110149862\t States: [-0.1843324   1.056631    0.10130773 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  469\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[15][19/30]\t Reward: -27.079737415611746\t States: [-0.1843324   1.065931    0.10196224 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  470\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[15][20/30]\t Reward: -26.917400142252447\t States: [-0.1843324   1.0545502   0.10147694 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  471\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[15][21/30]\t Reward: -26.975295772850515\t States: [-0.1843324   1.0622108   0.10128984 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  472\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[15][22/30]\t Reward: -26.711103251278402\t States: [-0.1843324   1.0420415   0.10066484 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  473\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[15][23/30]\t Reward: -26.79500870972872\t States: [-0.1843324   1.0498486   0.10072319 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  474\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[15][24/30]\t Reward: -26.96933724552393\t States: [-0.1843324   1.060412    0.10141013 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  475\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[15][25/30]\t Reward: -26.992618670761587\t States: [-0.1843324   1.0576444   0.10191971 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  476\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[15][26/30]\t Reward: -27.09758781462908\t States: [-0.1843324   1.0704918   0.10168466 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  477\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[15][27/30]\t Reward: -26.772043338119985\t States: [-0.1843324   1.0467514   0.10080326 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  478\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[15][28/30]\t Reward: -26.963106473982336\t States: [-0.1843324   1.0604337   0.10134565 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  479\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[15][29/30]\t Reward: -26.82951979905367\t States: [-0.1843324   1.0475293   0.10130022 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  480\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[16][0/30]\t Reward: -26.984556993544103\t States: [-0.1843324  1.0631403  0.1012895 62.223606 ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  481\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[16][1/30]\t Reward: -26.850821008980276\t States: [-0.1843324   1.0521803   0.10104814 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  482\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[16][2/30]\t Reward: -26.72578387528658\t States: [-0.1843324   1.0464481   0.10037099 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  483\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[16][3/30]\t Reward: -26.846296420395376\t States: [-0.1843324  1.0506523  0.1011557 62.223606 ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  484\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[16][4/30]\t Reward: -26.785684755146505\t States: [-0.1843324   1.0476516   0.10084964 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  485\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[16][5/30]\t Reward: -27.179263761341574\t States: [-0.1843324   1.0767766   0.10187294 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  486\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[16][6/30]\t Reward: -26.659425726234915\t States: [-0.1843324  1.0414462  0.1002076 62.223606 ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  487\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[16][7/30]\t Reward: -27.176930835545065\t States: [-0.1843324   1.078651    0.10166217 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  488\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[16][8/30]\t Reward: -26.763818046152593\t States: [-0.1843324   1.0449528   0.10090087 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  489\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[16][9/30]\t Reward: -26.805462768375875\t States: [-0.1843324   1.0469306   0.10111953 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  490\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[16][10/30]\t Reward: -26.8383783903718\t States: [-0.1843324  1.0525055  0.1008912 62.223606 ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  491\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[16][11/30]\t Reward: -26.8240981605649\t States: [-0.1843324  1.0521305  0.1007859 62.223606 ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  492\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[16][12/30]\t Reward: -26.922441950142385\t States: [-0.1843324   1.0542593   0.10155645 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  493\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[16][13/30]\t Reward: -26.97907887965441\t States: [-0.1843324   1.0611184   0.10143691 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  494\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[16][14/30]\t Reward: -26.873661508858206\t States: [-0.1843324   1.0548583   0.10100874 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  495\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[16][15/30]\t Reward: -26.99115299254656\t States: [-0.1843324   1.0640212   0.10126737 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  496\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[16][16/30]\t Reward: -26.64369084507227\t States: [-0.1843324   1.0352652   0.10066835 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  497\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[16][17/30]\t Reward: -26.955912938416006\t States: [-0.1843324   1.0602955   0.10128754 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  498\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[16][18/30]\t Reward: -26.904014727175237\t States: [-0.1843324   1.0543933   0.10135878 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  499\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[16][19/30]\t Reward: -26.853329470455648\t States: [-0.1843324   1.0527451   0.10101674 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  500\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[16][20/30]\t Reward: -26.917057266533376\t States: [-0.1843324   1.0535867   0.10156986 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  501\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[16][21/30]\t Reward: -26.787344941794874\t States: [-0.18433246  1.0524708   0.10113593 61.472004  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  502\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[16][22/30]\t Reward: -26.93383504465222\t States: [-0.18433245  1.0556895   0.10178411 61.96686   ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  503\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[16][23/30]\t Reward: -26.74560907229781\t States: [-0.18433248  1.0492485   0.1013151  61.197716  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  504\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[16][24/30]\t Reward: -26.681943312138316\t States: [-0.18433242  1.0413401   0.10054651 62.12048   ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  505\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[16][25/30]\t Reward: -26.287669438719746\t States: [-0.18433279  1.0566546   0.10110372 56.08908   ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  506\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[16][26/30]\t Reward: -25.26821463406086\t States: [-0.18433362  1.065558    0.101834   44.27392   ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  507\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[16][27/30]\t Reward: -26.372458274513484\t States: [-0.18433286  1.0688713   0.10194252 54.8765    ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  508\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[16][28/30]\t Reward: -25.914254305809735\t States: [-0.18433313  1.0647376   0.10166496 50.985394  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  509\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[16][29/30]\t Reward: -25.892134985923768\t States: [-0.18433309  1.0550537   0.10183205 51.5655    ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  510\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[17][0/30]\t Reward: -24.430995876193048\t States: [-0.18433398  1.0476784   0.10084164 38.68205   ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  511\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[17][1/30]\t Reward: -23.821846475005152\t States: [-0.1843347   1.0554693   0.10202229 30.630814  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  512\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[17][2/30]\t Reward: -23.374417404830453\t States: [-0.18433496  1.0549457   0.10081764 27.413534  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  513\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[17][3/30]\t Reward: -21.330247871428732\t States: [-0.18433793  1.0573652   0.10116243  6.385101  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  514\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[17][4/30]\t Reward: -21.78813720986247\t States: [-0.18433695  1.049737    0.10159725 11.291991  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  515\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[17][5/30]\t Reward: -21.053798540979624\t States: [-0.18433894  1.0616844   0.10158342  2.7676933 ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  516\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[17][6/30]\t Reward: -20.77256342574954\t States: [-0.18433969  1.0554049   0.10086384  1.302866  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  517\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[17][7/30]\t Reward: -20.803160953223703\t States: [-0.18433866  1.0417864   0.10021486  3.619671  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  518\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[17][8/30]\t Reward: -20.558487675040958\t States: [-0.1843409   1.0479976   0.10068959  0.0770933 ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  519\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[17][9/30]\t Reward: -20.757361931651833\t States: [-0.18434252  1.0590252   0.10143189  0.2207769 ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  520\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[17][10/30]\t Reward: -20.756686150133607\t States: [-0.18434396  1.0451769   0.10036281  2.6679332 ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  521\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[17][11/30]\t Reward: -20.598681825362146\t States: [-0.18434183  1.0512218   0.10084092  0.0052806 ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  522\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[17][12/30]\t Reward: -21.917675690650942\t States: [-0.18434572  1.0668466   0.10209835 10.375316  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  523\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[17][13/30]\t Reward: -20.64208601221442\t States: [-0.18434356  1.0382305   0.10063809  1.9412804 ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  524\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[17][14/30]\t Reward: -21.421888864934445\t States: [-0.18434533  1.0465847   0.10098271  8.559271  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  525\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[17][15/30]\t Reward: -22.795637095719577\t States: [-0.1843477   1.0372642   0.10057633 23.635187  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  526\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[17][16/30]\t Reward: -22.85321187123656\t States: [-0.18434738  1.0561352   0.10135441 21.545753  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  527\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[17][17/30]\t Reward: -22.626081499010322\t States: [-0.18434729  1.0463862   0.10059793 21.005823  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  528\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[17][18/30]\t Reward: -23.522863236367705\t States: [-0.18434796  1.0748249   0.10179664 25.931063  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  529\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[17][19/30]\t Reward: -25.049763262718916\t States: [-0.18435006  1.0617001   0.10147865 42.830536  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  530\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[17][20/30]\t Reward: -26.42993821695447\t States: [-0.184352    1.0397598   0.10024318 60.06179   ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  531\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[17][21/30]\t Reward: -26.17859776183963\t States: [-0.18435137  1.0594662   0.10163184 54.189083  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  532\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[17][22/30]\t Reward: -26.693361804336313\t States: [-0.18435214  1.0456734   0.10081598 61.531864  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  533\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[17][23/30]\t Reward: -26.978204462379217\t States: [-0.18435214  1.063291    0.10184634 61.588177  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  534\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[17][24/30]\t Reward: -26.661023792177442\t States: [-0.18435206  1.0468847   0.10109355 60.80979   ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  535\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[17][25/30]\t Reward: -26.66553550168872\t States: [-0.1843522   1.0344609   0.10098905 62.20178   ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  536\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[17][26/30]\t Reward: -27.046998570263383\t States: [-0.18435219  1.0670323   0.10152471 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  537\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[17][27/30]\t Reward: -26.90270168572664\t States: [-0.18435219  1.0572071   0.10106426 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  538\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[17][28/30]\t Reward: -26.902558336555956\t States: [-0.18435219  1.0538574   0.1013978  62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  539\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[17][29/30]\t Reward: -26.949154267609117\t States: [-0.18435219  1.0602059   0.10122891 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  540\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[18][0/30]\t Reward: -26.730036566555498\t States: [-0.18435219  1.0433744   0.10072088 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  541\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[18][1/30]\t Reward: -26.850496212542055\t States: [-0.18435219  1.052037    0.10105922 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  542\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[18][2/30]\t Reward: -26.935657391846178\t States: [-0.18435219  1.0532773   0.10178681 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  543\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[18][3/30]\t Reward: -27.036511133015154\t States: [-0.18435219  1.0638268   0.10174039 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  544\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[18][4/30]\t Reward: -26.87906024843454\t States: [-0.18435219  1.0518898   0.10135958 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  545\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[18][5/30]\t Reward: -26.858372519314287\t States: [-0.18435219  1.0511845   0.10122323 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  546\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[18][6/30]\t Reward: -26.937734017670152\t States: [-0.18435219  1.0596367   0.10117163 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  547\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[18][7/30]\t Reward: -26.680062095224855\t States: [-0.18435219  1.0448179   0.10007679 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  548\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[18][8/30]\t Reward: -27.02564222604036\t States: [-0.18435219  1.06587     0.10142738 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  549\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[18][9/30]\t Reward: -26.71419514209032\t States: [-0.18435219  1.042978    0.10060211 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  550\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[18][10/30]\t Reward: -27.074070999920366\t States: [-0.18435219  1.0690869   0.10158998 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  551\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[18][11/30]\t Reward: -26.92512405902147\t States: [-0.18435219  1.0538642   0.10162278 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  552\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[18][12/30]\t Reward: -26.922444681227205\t States: [-0.18435219  1.0589209   0.10109032 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  553\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[18][13/30]\t Reward: -27.038770447075365\t States: [-0.18435219  1.0667616   0.1014695  62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  554\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[18][14/30]\t Reward: -26.630151847898958\t States: [-0.18435219  1.0373573   0.10032374 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  555\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[18][15/30]\t Reward: -26.949057410061357\t States: [-0.18435219  1.0586532   0.10138321 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  556\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[18][16/30]\t Reward: -26.665447483360765\t States: [-0.18435219  1.0374479   0.10066764 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  557\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[18][17/30]\t Reward: -27.043971697390077\t States: [-0.18435219  1.0649157   0.10170611 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  558\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[18][18/30]\t Reward: -26.736624965965746\t States: [-0.18435219  1.0460504   0.10051917 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  559\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[18][19/30]\t Reward: -26.990769336521623\t States: [-0.18435219  1.0609949   0.10156617 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  560\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[18][20/30]\t Reward: -27.04669622570276\t States: [-0.18435219  1.0670898   0.10151594 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  561\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[18][21/30]\t Reward: -26.710202971994875\t States: [-0.18435219  1.0470166   0.10015833 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  562\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[18][22/30]\t Reward: -26.93382723122835\t States: [-0.18435219  1.0560681   0.10148942 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  563\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[18][23/30]\t Reward: -27.167392502129076\t States: [-0.18435219  1.0750796   0.10192393 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  564\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[18][24/30]\t Reward: -26.883554587662218\t States: [-0.18435219  1.0572574   0.10086776 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  565\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[18][25/30]\t Reward: -26.899429688751695\t States: [-0.18435219  1.0535729   0.10139497 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  566\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[18][26/30]\t Reward: -27.275183925926683\t States: [-0.18435219  1.0811821   0.10239159 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  567\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[18][27/30]\t Reward: -27.108438144028185\t States: [-0.18435219  1.0730027   0.10154207 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  568\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[18][28/30]\t Reward: -26.76424411922693\t States: [-0.18435219  1.0476732   0.10063308 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  569\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[18][29/30]\t Reward: -26.86140997201204\t States: [-0.18435219  1.0544333   0.10092872 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  570\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[19][0/30]\t Reward: -27.01326293736696\t States: [-0.18435219  1.0628496   0.10160562 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  571\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[19][1/30]\t Reward: -26.97784704953432\t States: [-0.18435219  1.0594684   0.10158959 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  572\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[19][2/30]\t Reward: -27.016990015804765\t States: [-0.18435219  1.064286    0.10149926 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  573\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[19][3/30]\t Reward: -26.858154217302797\t States: [-0.18435219  1.0514349   0.10119601 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  574\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[19][4/30]\t Reward: -26.964661310017107\t States: [-0.18435219  1.058492    0.10155538 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  575\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[19][5/30]\t Reward: -26.9498218396306\t States: [-0.18435219  1.0597929   0.10127689 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  576\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[19][6/30]\t Reward: -27.056203911602495\t States: [-0.18435219  1.0624901   0.10207099 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  577\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[19][7/30]\t Reward: -26.94743169337511\t States: [-0.18435219  1.0616335   0.10106893 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  578\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[19][8/30]\t Reward: -27.09001822263002\t States: [-0.18435219  1.0684164   0.10181651 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  579\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[19][9/30]\t Reward: -27.185157219469545\t States: [-0.18435219  1.0734665   0.10226288 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  580\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[19][10/30]\t Reward: -26.840012500584123\t States: [-0.18435219  1.0509874   0.10105935 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  581\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[19][11/30]\t Reward: -27.001091519892213\t States: [-0.18435219  1.0643032   0.10133856 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  582\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[19][12/30]\t Reward: -27.004805932343004\t States: [-0.18435219  1.0600264   0.10180338 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  583\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[19][13/30]\t Reward: -27.400943467915056\t States: [-0.18435219  1.0891079   0.10285661 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  584\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[19][14/30]\t Reward: -26.98133258014917\t States: [-0.18435219  1.0606369   0.1015076  62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  585\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[19][15/30]\t Reward: -26.746901551783083\t States: [-0.18435219  1.0465177   0.1005752  62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  586\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[19][16/30]\t Reward: -26.700842658579347\t States: [-0.18435219  1.0417503   0.10059135 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  587\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[19][17/30]\t Reward: -26.792052517235277\t States: [-0.18435219  1.0495768   0.10072081 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  588\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[19][18/30]\t Reward: -26.85341773420572\t States: [-0.18435219  1.0511044   0.10118169 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  589\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[19][19/30]\t Reward: -26.775940487682817\t States: [-0.18435219  1.0444338   0.10107398 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  590\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[19][20/30]\t Reward: -26.62332041054964\t States: [-0.18435219  1.0390716   0.10008401 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  591\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[19][21/30]\t Reward: -27.327216396629808\t States: [-0.18435219  1.0883762   0.10219251 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  592\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[19][22/30]\t Reward: -26.895814220011232\t States: [-0.18435219  1.0558771   0.10112839 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  593\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[19][23/30]\t Reward: -26.793674955666063\t States: [-0.18435219  1.0459094   0.10110377 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  594\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[19][24/30]\t Reward: -26.683592627346513\t States: [-0.18435219  1.0403912   0.10055476 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  595\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[19][25/30]\t Reward: -26.7655792632699\t States: [-0.18435219  1.0502058   0.10039317 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  596\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[19][26/30]\t Reward: -26.92013038188219\t States: [-0.18435219  1.0566455   0.10129471 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  597\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[19][27/30]\t Reward: -26.652740667164323\t States: [-0.18435219  1.0408957   0.1001958  62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  598\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[19][28/30]\t Reward: -26.80727703362703\t States: [-0.18435219  1.0484622   0.10098451 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  599\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[19][29/30]\t Reward: -26.762924025356767\t States: [-0.18435219  1.0479673   0.10059047 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  600\n",
            "input shape, \n",
            "------------training--------------\n",
            "-----------------evaluating---------------\n",
            "input shape:  torch.Size([1, 3, 1024])\n",
            "[20][0/30]\t Reward: -26.82242621958256\t States: [-0.1846214   1.024783    0.10070843 65.01907   ]\n",
            "input shape:  torch.Size([1, 3, 1024])\n",
            "[20][1/30]\t Reward: -25.378640296310184\t States: [-0.18459462  0.9752428   0.09870623 57.537434  ]\n",
            "input shape:  torch.Size([1, 3, 1024])\n",
            "[20][2/30]\t Reward: -27.387266603559254\t States: [-0.18460964  1.0845872   0.10380163 61.593853  ]\n",
            "input shape:  torch.Size([1, 3, 1024])\n",
            "[20][3/30]\t Reward: -26.213047038018704\t States: [-0.18460259  1.0424297   0.09821971 59.649334  ]\n",
            "input shape:  torch.Size([1, 3, 1024])\n",
            "[20][4/30]\t Reward: -27.060195985734463\t States: [-0.18457922  1.1534613   0.10182466 53.412712  ]\n",
            "input shape:  torch.Size([1, 3, 1024])\n",
            "[20][5/30]\t Reward: -26.903264552056786\t States: [-0.18460926  1.0269114   0.10485287 61.470177  ]\n",
            "---------------------------------------\n",
            "Evaluation over 6 episodes: -26.627473\n",
            "---------------------------------------\n",
            "------------testing policy-----------\n",
            "input shape:  torch.Size([1, 3, 1024])\n",
            "[20][0/30]\t Reward: -30.10984568178654\t States: [-0.18460709  1.2900162   0.1112287  60.849674  ]\n",
            "input shape:  torch.Size([1, 3, 1024])\n",
            "[20][1/30]\t Reward: -25.715147595405575\t States: [-0.18458533  1.019184    0.10019337 55.02125   ]\n",
            "input shape:  torch.Size([1, 3, 1024])\n",
            "[20][2/30]\t Reward: -28.375500888973473\t States: [-0.18462075  1.1229665   0.10660083 64.839066  ]\n",
            "input shape:  torch.Size([1, 3, 1024])\n",
            "[20][3/30]\t Reward: -25.80054073125124\t States: [-0.18460014  1.0216548   0.09683219 58.989277  ]\n",
            "input shape:  torch.Size([1, 3, 1024])\n",
            "[20][4/30]\t Reward: -26.225250321030614\t States: [-0.18461818  0.9841288   0.09973761 64.08356   ]\n",
            "input shape:  torch.Size([1, 3, 1024])\n",
            "[20][5/30]\t Reward: -27.74189367040992\t States: [-0.1845995  1.1356807  0.1049822 58.850204 ]\n",
            "input shape:  torch.Size([1, 3, 1024])\n",
            "[20][6/30]\t Reward: -24.994781485944987\t States: [-0.18456496  1.0285681   0.09731089 49.761658  ]\n",
            "input shape:  torch.Size([1, 3, 1024])\n",
            "[20][7/30]\t Reward: -29.020622495561838\t States: [-0.18458761  1.2636638   0.10819955 55.621838  ]\n",
            "input shape:  torch.Size([1, 3, 1024])\n",
            "[20][8/30]\t Reward: -28.05214339464903\t States: [-0.18461403  1.1343267   0.10419329 62.87701   ]\n",
            "input shape:  torch.Size([1, 3, 1024])\n",
            "[20][9/30]\t Reward: -26.034965031594037\t States: [-0.18461458  1.0242568   0.09489297 63.012535  ]\n",
            "input shape:  torch.Size([1, 3, 1024])\n",
            "[20][10/30]\t Reward: -26.32570515975356\t States: [-0.18460523  1.057932    0.09709404 60.351345  ]\n",
            "input shape:  torch.Size([1, 3, 1024])\n",
            "[20][11/30]\t Reward: -25.505048672109844\t States: [-0.18459357  0.96712935  0.10104336 57.275734  ]\n",
            "---------------------------------------\n",
            "Evaluation over 12 episodes: -26.991787\n",
            "---------------------------------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[20][0/30]\t Reward: -27.073261419832704\t States: [-0.18435219  1.0660177   0.1018888  62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  601\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[20][1/30]\t Reward: -26.796481440365312\t States: [-0.18435219  1.0511377   0.100609   62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  602\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[20][2/30]\t Reward: -26.59026248246431\t States: [-0.18435219  1.0325799   0.10040259 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  603\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[20][3/30]\t Reward: -26.897135803997514\t States: [-0.18435219  1.0539308   0.10133624 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  604\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[20][4/30]\t Reward: -26.9880218604207\t States: [-0.18435219  1.0647355   0.10116462 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  605\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[20][5/30]\t Reward: -27.11344672232866\t States: [-0.18435219  1.0692248   0.10196994 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  606\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[20][6/30]\t Reward: -26.9808473983407\t States: [-0.18435219  1.0594469   0.10162174 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  607\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[20][7/30]\t Reward: -26.813495288193224\t States: [-0.18435219  1.0487238   0.10102053 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  608\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[20][8/30]\t Reward: -27.01091078907251\t States: [-0.18435219  1.0634189   0.10152518 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  609\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[20][9/30]\t Reward: -26.9390052357316\t States: [-0.18435219  1.0555302   0.10159499 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  610\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[20][10/30]\t Reward: -26.867466399967668\t States: [-0.18435219  1.0516853   0.10126409 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  611\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[20][11/30]\t Reward: -26.462527344524858\t States: [-0.18435219  1.0249926   0.09988397 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  612\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[20][12/30]\t Reward: -26.82196764141321\t States: [-0.18435219  1.0498621   0.10099142 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  613\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[20][13/30]\t Reward: -26.5963920751214\t States: [-0.18435219  1.0352103   0.10020085 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  614\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[20][14/30]\t Reward: -26.480051259100435\t States: [-0.18435219  1.0269228   0.09986619 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  615\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[20][15/30]\t Reward: -26.937487254440782\t States: [-0.18435219  1.0582995   0.10130288 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  616\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[20][16/30]\t Reward: -26.86964971810579\t States: [-0.18435219  1.0564572   0.10080874 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  617\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[20][17/30]\t Reward: -26.793292442858217\t States: [-0.18435219  1.047641    0.10092678 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  618\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[20][18/30]\t Reward: -27.069302628338335\t States: [-0.18435219  1.0678352   0.10166746 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  619\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[20][19/30]\t Reward: -26.92601112514734\t States: [-0.18435219  1.0612887   0.1008892  62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  620\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[20][20/30]\t Reward: -26.84665379911661\t States: [-0.18435219  1.0522454   0.10099996 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  621\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[20][21/30]\t Reward: -27.121161202490327\t States: [-0.18435219  1.071322    0.10183737 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  622\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[20][22/30]\t Reward: -26.829521487057207\t States: [-0.18435219  1.048399    0.10121328 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  623\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[20][23/30]\t Reward: -26.698192189037798\t States: [-0.18435219  1.0404677   0.10069311 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  624\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[20][24/30]\t Reward: -26.99671430379152\t States: [-0.18435219  1.0630974   0.10141537 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  625\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[20][25/30]\t Reward: -26.785862872898576\t States: [-0.18435219  1.048251    0.10079148 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  626\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[20][26/30]\t Reward: -27.096975872814653\t States: [-0.18435219  1.0668844   0.10203928 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  627\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[20][27/30]\t Reward: -27.02756000548601\t States: [-0.18435219  1.0645677   0.10157679 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  628\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[20][28/30]\t Reward: -27.105561921894548\t States: [-0.18435219  1.0662222   0.10219136 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  629\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[20][29/30]\t Reward: -26.748087982237337\t States: [-0.18435219  1.0444058   0.10079826 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  630\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[21][0/30]\t Reward: -27.245392928421495\t States: [-0.18435219  1.081118    0.10210009 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  631\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[21][1/30]\t Reward: -26.927032450735567\t States: [-0.18435219  1.05642     0.10138629 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  632\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[21][2/30]\t Reward: -26.716058979332445\t States: [-0.18435219  1.0447276   0.10044579 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  633\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[21][3/30]\t Reward: -27.07015259057283\t States: [-0.18435219  1.0682945   0.10163003 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  634\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[21][4/30]\t Reward: -26.959028969109056\t States: [-0.18435219  1.0584292   0.10150532 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  635\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[21][5/30]\t Reward: -27.107652554810045\t States: [-0.18435219  1.0701841   0.10181607 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  636\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[21][6/30]\t Reward: -26.962368021309373\t States: [-0.18435219  1.0633646   0.10104518 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  637\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[21][7/30]\t Reward: -26.946009228527544\t States: [-0.18435219  1.0612434   0.10109371 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  638\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[21][8/30]\t Reward: -26.94636715441942\t States: [-0.18435219  1.0596411   0.10125752 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  639\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[21][9/30]\t Reward: -26.77270455151796\t States: [-0.18435219  1.0429131   0.1011937  62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  640\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[21][10/30]\t Reward: -26.75406170874834\t States: [-0.18435219  1.0429727   0.10100131 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  641\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[21][11/30]\t Reward: -26.83060629159212\t States: [-0.18435219  1.0492585   0.10113817 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  642\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[21][12/30]\t Reward: -26.81019348889589\t States: [-0.18435219  1.0469093   0.10116896 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  643\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[21][13/30]\t Reward: -27.139144817888734\t States: [-0.18435219  1.0738041   0.10176899 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  644\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[21][14/30]\t Reward: -26.89872367173433\t States: [-0.18435219  1.0576992   0.10097528 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  645\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[21][15/30]\t Reward: -27.028196881115434\t States: [-0.18435219  1.064698    0.10157013 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  646\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[21][16/30]\t Reward: -26.918059120476244\t States: [-0.18435219  1.0612005   0.1008185  62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  647\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[21][17/30]\t Reward: -26.63082314521074\t States: [-0.18435219  1.0383867   0.10022752 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  648\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[21][18/30]\t Reward: -26.934372613728044\t States: [-0.18435219  1.058497    0.10125199 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  649\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[21][19/30]\t Reward: -26.652750203907488\t States: [-0.18435219  1.0364573   0.10063973 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  650\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[21][20/30]\t Reward: -26.868997196257112\t States: [-0.18435219  1.0526117   0.10118676 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  651\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[21][21/30]\t Reward: -26.90475804597139\t States: [-0.18435219  1.0619117   0.10061437 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  652\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[21][22/30]\t Reward: -26.97919471055269\t States: [-0.18435219  1.0611681   0.1014331  62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  653\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[21][23/30]\t Reward: -27.1302075484395\t States: [-0.18435219  1.0691861   0.10214143 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  654\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[21][24/30]\t Reward: -26.95680392771959\t States: [-0.18435219  1.0582261   0.10150339 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  655\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[21][25/30]\t Reward: -26.81076688557863\t States: [-0.18435219  1.0521475   0.10065088 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  656\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[21][26/30]\t Reward: -27.03994093328714\t States: [-0.18435219  1.0675395   0.10140342 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  657\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[21][27/30]\t Reward: -26.73692209511995\t States: [-0.18435219  1.0456091   0.10056627 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  658\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[21][28/30]\t Reward: -26.99919862538576\t States: [-0.18435219  1.0631366   0.10143629 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  659\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[21][29/30]\t Reward: -26.935882399380205\t States: [-0.18435219  1.0565442   0.10146236 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  660\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[22][0/30]\t Reward: -26.672473976910112\t States: [-0.18435219  1.0402098   0.10046172 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  661\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[22][1/30]\t Reward: -26.86663491517305\t States: [-0.18435219  1.053877    0.10103661 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  662\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[22][2/30]\t Reward: -26.79686857253313\t States: [-0.18435219  1.0471306   0.10101359 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  663\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[22][3/30]\t Reward: -26.88933921843767\t States: [-0.18435219  1.055176    0.10113375 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  664\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[22][4/30]\t Reward: -26.989788840115068\t States: [-0.18435219  1.0639954   0.10125631 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  665\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[22][5/30]\t Reward: -27.011010775864122\t States: [-0.18435219  1.063397    0.10152836 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  666\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[22][6/30]\t Reward: -26.808136532604692\t States: [-0.18435219  1.0497557   0.10086375 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  667\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[22][7/30]\t Reward: -26.770167479813097\t States: [-0.18435219  1.0485091   0.10060872 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  668\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[22][8/30]\t Reward: -26.877281198799608\t States: [-0.18435219  1.0554913   0.10098164 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  669\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[22][9/30]\t Reward: -26.82739538937807\t States: [-0.18435219  1.0504916   0.10098276 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  670\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[22][10/30]\t Reward: -26.80467260867357\t States: [-0.18435219  1.0465827   0.10114641 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  671\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[22][11/30]\t Reward: -26.876095066368578\t States: [-0.18435219  1.0502104   0.10149787 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  672\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[22][12/30]\t Reward: -26.706679145395753\t States: [-0.18435219  1.042294    0.10059535 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  673\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[22][13/30]\t Reward: -26.878559420406816\t States: [-0.18435219  1.0543905   0.1011045  62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  674\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[22][14/30]\t Reward: -26.837564835846422\t States: [-0.18435219  1.0484855   0.10128506 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  675\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[22][15/30]\t Reward: -27.013043592274187\t States: [-0.18435219  1.0621142   0.10167697 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  676\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[22][16/30]\t Reward: -26.836128363907335\t States: [-0.18435219  1.0496663   0.10115261 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  677\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[22][17/30]\t Reward: -26.723493317663667\t States: [-0.18435219  1.0428586   0.10070703 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  678\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[22][18/30]\t Reward: -26.85635326296091\t States: [-0.18435219  1.0526088   0.10106061 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  679\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[22][19/30]\t Reward: -26.74652172118425\t States: [-0.18435219  1.0464083   0.10058235 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  680\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[22][20/30]\t Reward: -26.982710490524767\t States: [-0.18435219  1.0568799   0.10189708 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  681\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[22][21/30]\t Reward: -26.924710849821565\t States: [-0.18435219  1.0566429   0.10134078 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  682\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[22][22/30]\t Reward: -26.50966359168291\t States: [-0.18435219  1.0304431   0.09981029 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  683\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[22][23/30]\t Reward: -26.903661618530748\t States: [-0.18435219  1.052584    0.10153617 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  684\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[22][24/30]\t Reward: -27.03906131774187\t States: [-0.18435219  1.0606157   0.10208701 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  685\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[22][25/30]\t Reward: -27.10195226460695\t States: [-0.18435219  1.0703208   0.1017454  62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  686\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[22][26/30]\t Reward: -26.868514845669267\t States: [-0.18435219  1.0517327   0.10126984 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  687\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[22][27/30]\t Reward: -26.946677098572252\t States: [-0.18435219  1.0595654   0.10126819 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  688\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[22][28/30]\t Reward: -26.70390544325113\t States: [-0.18435219  1.0425947   0.10053755 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  689\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[22][29/30]\t Reward: -27.03351897984743\t States: [-0.18435219  1.0666652   0.10142663 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  690\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[23][0/30]\t Reward: -26.9064344266057\t States: [-0.18435219  1.0592682   0.10089548 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  691\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[23][1/30]\t Reward: -26.758428345024583\t States: [-0.18435219  1.0439732   0.10094492 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  692\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[23][2/30]\t Reward: -26.888749132454393\t States: [-0.18435219  1.0566292   0.10098253 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  693\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[23][3/30]\t Reward: -27.055503557026384\t States: [-0.18435219  1.0663251   0.10168049 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  694\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[23][4/30]\t Reward: -26.88602311402559\t States: [-0.18435219  1.052348    0.10138339 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  695\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[23][5/30]\t Reward: -27.08911029487848\t States: [-0.18435219  1.0676229   0.10188677 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  696\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[23][6/30]\t Reward: -27.03351689368486\t States: [-0.18435219  1.0631845   0.10177468 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  697\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[23][7/30]\t Reward: -27.281599471867082\t States: [-0.18435219  1.079693    0.10260466 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  698\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[23][8/30]\t Reward: -26.96069417387247\t States: [-0.18435219  1.0548667   0.10187823 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  699\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[23][9/30]\t Reward: -26.710160503685472\t States: [-0.18435219  1.0481479   0.10004477 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  700\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[23][10/30]\t Reward: -26.9952337244153\t States: [-0.18435219  1.0586357   0.10184672 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  701\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[23][11/30]\t Reward: -26.90456820517778\t States: [-0.18435219  1.0551623   0.10128741 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  702\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[23][12/30]\t Reward: -26.794233153164384\t States: [-0.18435219  1.0503681   0.10066348 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  703\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[23][13/30]\t Reward: -26.698285172283647\t States: [-0.18435219  1.0413431   0.1006065  62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  704\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[23][14/30]\t Reward: -26.700622717440126\t States: [-0.18435219  1.040161    0.10074808 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  705\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[23][15/30]\t Reward: -26.954430470764635\t States: [-0.18435219  1.0569689   0.10160537 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  706\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[23][16/30]\t Reward: -26.96068359404802\t States: [-0.18435219  1.0619397   0.10117082 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  707\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[23][17/30]\t Reward: -26.848509738743303\t States: [-0.18435219  1.0544126   0.1008018  62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  708\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[23][18/30]\t Reward: -26.970608661472795\t States: [-0.18435219  1.062114    0.10125265 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  709\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[23][19/30]\t Reward: -26.60704849153757\t States: [-0.18435219  1.0382439   0.10000405 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  710\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[23][20/30]\t Reward: -26.96640504390001\t States: [-0.18435219  1.0615495   0.10126705 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  711\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[23][21/30]\t Reward: -26.944789419472215\t States: [-0.18435219  1.0571698   0.10148887 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  712\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[23][22/30]\t Reward: -26.46148128300905\t States: [-0.18435219  1.0271509   0.09965768 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  713\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[23][23/30]\t Reward: -26.625116000473497\t States: [-0.18435219  1.033936    0.10061552 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  714\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[23][24/30]\t Reward: -26.617667208015916\t States: [-0.18435219  1.0384045   0.10009418 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  715\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[23][25/30]\t Reward: -26.660655567944048\t States: [-0.18435219  1.040955    0.10026902 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  716\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[23][26/30]\t Reward: -27.2136933901906\t States: [-0.18435219  1.076978    0.1021971  62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  717\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[23][27/30]\t Reward: -26.902881840765474\t States: [-0.18435219  1.0558646   0.10120032 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  718\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[23][28/30]\t Reward: -26.746904979050157\t States: [-0.18435219  1.0432706   0.10089995 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  719\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[23][29/30]\t Reward: -27.009248564541338\t States: [-0.18435219  1.062923    0.10155815 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  720\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[24][0/30]\t Reward: -26.87118483573198\t States: [-0.18435219  1.053695    0.10110031 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  721\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[24][1/30]\t Reward: -26.763179729282854\t States: [-0.18435219  1.0442172   0.10096803 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  722\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[24][2/30]\t Reward: -26.62122649937868\t States: [-0.18435219  1.0367447   0.10029575 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  723\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[24][3/30]\t Reward: -27.08814544469118\t States: [-0.18435219  1.0698342   0.10165599 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  724\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[24][4/30]\t Reward: -27.068950662910936\t States: [-0.18435219  1.0704186   0.10140561 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  725\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[24][5/30]\t Reward: -27.038126418888567\t States: [-0.18435219  1.0637964   0.10175958 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  726\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[24][6/30]\t Reward: -27.19093454867601\t States: [-0.18435219  1.0767289   0.10199441 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  727\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[24][7/30]\t Reward: -27.333458940088747\t States: [-0.18435219  1.0866084   0.10243171 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  728\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[24][8/30]\t Reward: -26.78885651618242\t States: [-0.18435219  1.0530385   0.10034268 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  729\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[24][9/30]\t Reward: -26.74486053973436\t States: [-0.18435219  1.0425255   0.10095401 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  730\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[24][10/30]\t Reward: -27.04046351701021\t States: [-0.18435219  1.0635041   0.10181218 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  731\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[24][11/30]\t Reward: -26.961767802536485\t States: [-0.18435219  1.0596291   0.10141273 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  732\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[24][12/30]\t Reward: -26.775715182125566\t States: [-0.18435219  1.0461416   0.10090095 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  733\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[24][13/30]\t Reward: -26.93958399683237\t States: [-0.18435219  1.0593452   0.10121927 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  734\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[24][14/30]\t Reward: -27.088795433342455\t States: [-0.18435219  1.0689734   0.10174857 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  735\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[24][15/30]\t Reward: -27.008971104919908\t States: [-0.18435219  1.0607487   0.1017728  62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  736\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[24][16/30]\t Reward: -26.996117959320543\t States: [-0.18435219  1.0615829   0.10156085 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  737\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[24][17/30]\t Reward: -27.1158511736989\t States: [-0.18435219  1.070571    0.10185938 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  738\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[24][18/30]\t Reward: -26.879648397266863\t States: [-0.18435219  1.0543185   0.10112259 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  739\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[24][19/30]\t Reward: -26.80718017607927\t States: [-0.18435219  1.0484365   0.10098611 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  740\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[24][20/30]\t Reward: -26.616131196320055\t States: [-0.18435219  1.0360678   0.10031249 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  741\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[24][21/30]\t Reward: -27.238344828188417\t States: [-0.18435219  1.0790809   0.10223331 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  742\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[24][22/30]\t Reward: -26.909271309673784\t States: [-0.18435219  1.0577502   0.10107565 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  743\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[24][23/30]\t Reward: -27.07197515159845\t States: [-0.18435219  1.0688962   0.10158809 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  744\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[24][24/30]\t Reward: -26.73064870625734\t States: [-0.18435219  1.0441971   0.10064474 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  745\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[24][25/30]\t Reward: -26.749054173529146\t States: [-0.18435219  1.0466902   0.10057948 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  746\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[24][26/30]\t Reward: -26.966936419308183\t States: [-0.18435219  1.0573226   0.10169506 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  747\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[24][27/30]\t Reward: -26.6394549408555\t States: [-0.18435219  1.0374478   0.10040773 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  748\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[24][28/30]\t Reward: -27.110865841209886\t States: [-0.18435219  1.0718671   0.10167991 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  749\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[24][29/30]\t Reward: -26.976802180111406\t States: [-0.18435219  1.0595627   0.10156971 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  750\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[25][0/30]\t Reward: -26.733262816965578\t States: [-0.18435219  1.0408856   0.10100203 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  751\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[25][1/30]\t Reward: -26.999166885912416\t States: [-0.18435219  1.0626113   0.10148849 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  752\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[25][2/30]\t Reward: -26.89311755686998\t States: [-0.18435219  1.0526317   0.10142596 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  753\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[25][3/30]\t Reward: -27.03826976805925\t States: [-0.18435219  1.0637486   0.1017658  62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  754\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[25][4/30]\t Reward: -26.563750932514665\t States: [-0.18435219  1.0329462   0.10010085 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  755\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[25][5/30]\t Reward: -27.133208940327165\t States: [-0.18435219  1.0733261   0.10175744 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  756\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[25][6/30]\t Reward: -27.046211490929124\t States: [-0.18435219  1.0657748   0.10164259 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  757\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[25][7/30]\t Reward: -26.870556900799272\t States: [-0.18435219  1.0520769   0.10125583 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  758\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[25][8/30]\t Reward: -26.898458878099916\t States: [-0.18435219  1.0553414   0.10120841 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  759\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[25][9/30]\t Reward: -27.0664164224267\t States: [-0.18435219  1.0666511   0.10175701 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  760\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[25][10/30]\t Reward: -26.85922978311777\t States: [-0.18435219  1.0510786   0.1012424  62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  761\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[25][11/30]\t Reward: -27.098971436321733\t States: [-0.18435219  1.068524    0.10189527 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  762\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[25][12/30]\t Reward: -27.111587355434892\t States: [-0.18435219  1.0705223   0.1018216  62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  763\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[25][13/30]\t Reward: -27.074176053106783\t States: [-0.18435219  1.070214    0.10147832 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  764\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[25][14/30]\t Reward: -26.72306073695421\t States: [-0.18435219  1.0425879   0.10072978 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  765\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[25][15/30]\t Reward: -26.580362001955507\t States: [-0.18435219  1.0325117   0.10031041 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  766\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[25][16/30]\t Reward: -26.79396075993776\t States: [-0.18435219  1.0472578   0.10097179 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  767\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[25][17/30]\t Reward: -26.76125151902437\t States: [-0.18435219  1.0465549   0.10071498 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  768\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[25][18/30]\t Reward: -26.87380460888147\t States: [-0.18435219  1.0533572   0.10116028 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  769\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[25][19/30]\t Reward: -26.816376576721666\t States: [-0.18435219  1.0487938   0.10104235 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  770\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[25][20/30]\t Reward: -26.821974048912523\t States: [-0.18435219  1.0538182   0.10059588 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  771\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[25][21/30]\t Reward: -26.768803725540636\t States: [-0.18435219  1.0478715   0.10065885 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  772\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[25][22/30]\t Reward: -26.998753080666063\t States: [-0.18435219  1.066388    0.10110669 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  773\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[25][23/30]\t Reward: -27.07581860810518\t States: [-0.18435219  1.0682716   0.10168898 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  774\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[25][24/30]\t Reward: -26.912807653248308\t States: [-0.18435219  1.0553141   0.10135463 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  775\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[25][25/30]\t Reward: -26.904617677032945\t States: [-0.18435219  1.056694    0.10113473 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  776\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[25][26/30]\t Reward: -26.922110448181627\t States: [-0.18435219  1.0578777   0.1011913  62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  777\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[25][27/30]\t Reward: -26.792900095283983\t States: [-0.18435219  1.0479467   0.10089229 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  778\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[25][28/30]\t Reward: -27.08852154999971\t States: [-0.18435219  1.0674909   0.10189408 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  779\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[25][29/30]\t Reward: -26.943215707838533\t States: [-0.18435219  1.0589249   0.10129762 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  780\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[26][0/30]\t Reward: -26.82372195512056\t States: [-0.18435219  1.0515938   0.1008358  62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  781\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[26][1/30]\t Reward: -26.70791966706514\t States: [-0.18435219  1.0428424   0.10055292 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  782\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[26][2/30]\t Reward: -26.776409874260423\t States: [-0.18435219  1.0499741   0.10052465 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  783\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[26][3/30]\t Reward: -26.968573311865327\t States: [-0.18435219  1.0586357   0.10158012 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  784\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[26][4/30]\t Reward: -27.02190397173166\t States: [-0.18435219  1.0676196   0.10121504 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  785\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[26][5/30]\t Reward: -26.981132308542726\t States: [-0.18435219  1.0567378   0.1018955  62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  786\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[26][6/30]\t Reward: -26.902169118225572\t States: [-0.18435219  1.0562578   0.10115387 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  787\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[26][7/30]\t Reward: -26.984836588203905\t States: [-0.18435219  1.0590931   0.10169701 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  788\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[26][8/30]\t Reward: -27.123131285011766\t States: [-0.18435219  1.070505    0.10193877 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  789\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[26][9/30]\t Reward: -26.82195765763521\t States: [-0.18435219  1.0523704   0.10074049 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  790\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[26][10/30]\t Reward: -26.670360396206377\t States: [-0.18435219  1.0380994   0.10065162 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  791\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[26][11/30]\t Reward: -26.870594004690645\t States: [-0.18435219  1.0541003   0.10105387 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  792\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[26][12/30]\t Reward: -26.962313036024568\t States: [-0.18435219  1.0579069   0.1015904  62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  793\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[26][13/30]\t Reward: -26.833872030079363\t States: [-0.18435219  1.0509229   0.10100439 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  794\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[26][14/30]\t Reward: -27.053835521042345\t States: [-0.18435219  1.0687596   0.10142036 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  795\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[26][15/30]\t Reward: -26.7919467189908\t States: [-0.18435219  1.0488192   0.10079551 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  796\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[26][16/30]\t Reward: -27.03784836322069\t States: [-0.18435219  1.0661052   0.10152592 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  797\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[26][17/30]\t Reward: -27.153065333664415\t States: [-0.18435219  1.0745889   0.10182972 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  798\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[26][18/30]\t Reward: -27.069281170666216\t States: [-0.18435219  1.0695157   0.1014992  62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  799\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[26][19/30]\t Reward: -26.59567875653505\t States: [-0.18435219  1.0353516   0.10017958 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  800\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[26][20/30]\t Reward: -26.7313359478116\t States: [-0.18435219  1.0471909   0.10035223 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  801\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[26][21/30]\t Reward: -26.937966475784776\t States: [-0.18435219  1.0566398   0.10147364 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  802\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[26][22/30]\t Reward: -26.82645929843187\t States: [-0.18435219  1.0484806   0.10117449 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  803\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[26][23/30]\t Reward: -26.804945895969865\t States: [-0.18435219  1.0478842   0.101019   62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  804\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[26][24/30]\t Reward: -27.06140143662691\t States: [-0.18435219  1.0653857   0.1018334  62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  805\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[26][25/30]\t Reward: -26.80860442906618\t States: [-0.18435219  1.0491185   0.10093215 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  806\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[26][26/30]\t Reward: -26.870764026939867\t States: [-0.18435219  1.0530694   0.10115866 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  807\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[26][27/30]\t Reward: -26.8189619281888\t States: [-0.18435219  1.0526037   0.10068721 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  808\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[26][28/30]\t Reward: -26.997755596935747\t States: [-0.18435219  1.0588518   0.10185033 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  809\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[26][29/30]\t Reward: -27.178668657839296\t States: [-0.18435219  1.0702481   0.10251983 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  810\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[27][0/30]\t Reward: -26.990399489700792\t States: [-0.18435219  1.0602112   0.10164084 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  811\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[27][1/30]\t Reward: -26.598200480043886\t States: [-0.18435219  1.0344851   0.10029145 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  812\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[27][2/30]\t Reward: -26.819607148468492\t States: [-0.18435219  1.0513884   0.10081519 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  813\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[27][3/30]\t Reward: -26.864350567162035\t States: [-0.18435219  1.0508503   0.10131644 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  814\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[27][4/30]\t Reward: -26.784137169420717\t States: [-0.18435219  1.0496813   0.1006312  62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  815\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[27][5/30]\t Reward: -27.052713165581224\t States: [-0.18435219  1.0650374   0.10178135 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  816\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[27][6/30]\t Reward: -26.82041419535875\t States: [-0.18435219  1.0505816   0.10090394 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  817\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[27][7/30]\t Reward: -26.944355795681474\t States: [-0.18435219  1.0615191   0.1010496  62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  818\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[27][8/30]\t Reward: -26.925220320522783\t States: [-0.18435219  1.0567362   0.10133654 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  819\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[27][9/30]\t Reward: -26.978473345339296\t States: [-0.18435219  1.0585744   0.10168525 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  820\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[27][10/30]\t Reward: -27.11572421580553\t States: [-0.18435219  1.0714347   0.10177173 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  821\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[27][11/30]\t Reward: -26.844407151043413\t States: [-0.18435219  1.0506666   0.10113537 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  822\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[27][12/30]\t Reward: -26.613763401806352\t States: [-0.18435219  1.037664    0.10012919 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  823\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[27][13/30]\t Reward: -26.64955643802881\t States: [-0.18435219  1.0382358   0.10042994 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  824\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[27][14/30]\t Reward: -26.935168335735796\t States: [-0.18435219  1.0590292   0.10120672 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  825\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[27][15/30]\t Reward: -26.856886426508424\t States: [-0.18435219  1.0542111   0.10090571 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  826\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[27][16/30]\t Reward: -26.85016764193773\t States: [-0.18435219  1.0537089   0.10088874 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  827\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[27][17/30]\t Reward: -27.151637206375597\t States: [-0.18435219  1.0749605   0.10177828 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  828\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[27][18/30]\t Reward: -26.927771250307558\t States: [-0.18435219  1.053962    0.10163947 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  829\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[27][19/30]\t Reward: -26.903191784918306\t States: [-0.18435219  1.0554086   0.10124902 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  830\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[27][20/30]\t Reward: -26.800229082405565\t States: [-0.18435219  1.047559    0.10100435 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  831\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[27][21/30]\t Reward: -26.826140711605547\t States: [-0.18435219  1.0490813   0.10111123 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  832\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[27][22/30]\t Reward: -26.831940541565416\t States: [-0.18435219  1.0506828   0.10100909 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  833\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[27][23/30]\t Reward: -26.99423743277788\t States: [-0.18435219  1.0606292   0.10163741 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  834\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[27][24/30]\t Reward: -26.893776486217973\t States: [-0.18435219  1.0551744   0.10117829 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  835\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[27][25/30]\t Reward: -26.90837545186281\t States: [-0.18435219  1.0516433   0.10167739 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  836\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[27][26/30]\t Reward: -27.067502568066118\t States: [-0.18435219  1.0640163   0.10203135 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  837\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[27][27/30]\t Reward: -26.90313069015741\t States: [-0.18435219  1.0587113   0.10091814 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  838\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[27][28/30]\t Reward: -26.852392832338808\t States: [-0.18435219  1.0509559   0.1011863  62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  839\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[27][29/30]\t Reward: -27.089092264473436\t States: [-0.18435219  1.069502    0.10169868 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  840\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[28][0/30]\t Reward: -26.755513677895067\t States: [-0.18435219  1.0456296   0.10075013 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  841\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[28][1/30]\t Reward: -26.798205206692217\t States: [-0.18435219  1.0496846   0.10077155 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  842\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[28][2/30]\t Reward: -27.0099945166707\t States: [-0.18435219  1.0624392   0.10161398 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  843\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[28][3/30]\t Reward: -26.85916839033365\t States: [-0.18435219  1.0518976   0.10115988 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  844\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[28][4/30]\t Reward: -26.86629814893007\t States: [-0.18435219  1.0511584   0.1013051  62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  845\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[28][5/30]\t Reward: -26.734451184570787\t States: [-0.18435219  1.044652    0.10063727 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  846\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[28][6/30]\t Reward: -26.88053069502115\t States: [-0.18435219  1.0565629   0.10090698 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  847\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[28][7/30]\t Reward: -26.872906217873094\t States: [-0.18435219  1.0524974   0.10123728 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  848\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[28][8/30]\t Reward: -26.736233512461183\t States: [-0.18435219  1.0433475   0.10078555 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  849\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[28][9/30]\t Reward: -26.86945123463869\t States: [-0.18435219  1.0516603   0.10128644 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  850\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[28][10/30]\t Reward: -26.723961363136766\t States: [-0.18435219  1.0391008   0.1010875  62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  851\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[28][11/30]\t Reward: -26.89098281651735\t States: [-0.18435219  1.0546378   0.10120401 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  852\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[28][12/30]\t Reward: -26.889824102222917\t States: [-0.18435219  1.0548581   0.10117039 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  853\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[28][13/30]\t Reward: -27.027967999279497\t States: [-0.18435219  1.0630312   0.10173452 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  854\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[28][14/30]\t Reward: -26.688058207333086\t States: [-0.18435219  1.0409039   0.10054815 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  855\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[28][15/30]\t Reward: -26.938460449278352\t States: [-0.18435219  1.0603371   0.10110886 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  856\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[28][16/30]\t Reward: -27.064075300991533\t States: [-0.18435219  1.0634829   0.10205042 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  857\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[28][17/30]\t Reward: -26.90721465140581\t States: [-0.18435219  1.0571525   0.10111485 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  858\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[28][18/30]\t Reward: -26.713348458111284\t States: [-0.18435219  1.0413468   0.10075676 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  859\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[28][19/30]\t Reward: -27.157517502605913\t States: [-0.18435219  1.0747601   0.10185713 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  860\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[28][20/30]\t Reward: -26.86012549191713\t States: [-0.18435219  1.0542319   0.10093603 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  861\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[28][21/30]\t Reward: -26.975838373005388\t States: [-0.18435219  1.0612434   0.101392   62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  862\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[28][22/30]\t Reward: -27.08814410358667\t States: [-0.18435219  1.0681292   0.10182648 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  863\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[28][23/30]\t Reward: -27.04614801198244\t States: [-0.18435219  1.065163    0.10170314 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  864\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[28][24/30]\t Reward: -26.546946893036363\t States: [-0.18435219  1.0314674   0.10008068 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  865\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[28][25/30]\t Reward: -26.91237417846918\t States: [-0.18435219  1.0581294   0.10106876 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  866\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[28][26/30]\t Reward: -27.11299998551607\t States: [-0.18435219  1.0710343   0.10178453 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  867\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[28][27/30]\t Reward: -26.55561445146799\t States: [-0.18435219  1.0296786   0.10034624 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  868\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[28][28/30]\t Reward: -26.837437579929826\t States: [-0.18435219  1.0472996   0.10140237 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  869\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[28][29/30]\t Reward: -26.734233627617357\t States: [-0.18435219  1.0447724   0.10062306 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  870\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[29][0/30]\t Reward: -26.872934530079363\t States: [-0.18435219  1.0533617   0.10115114 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  871\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[29][1/30]\t Reward: -26.86856878787279\t States: [-0.18435219  1.0516866   0.10127498 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  872\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[29][2/30]\t Reward: -27.040050307810304\t States: [-0.18435219  1.0646698   0.10169148 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  873\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[29][3/30]\t Reward: -26.86456842213869\t States: [-0.18435219  1.0524875   0.10115489 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  874\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[29][4/30]\t Reward: -26.82015595823526\t States: [-0.18435219  1.0509248   0.10086704 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  875\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[29][5/30]\t Reward: -26.628972420990465\t States: [-0.18435219  1.0355608   0.1004916  62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  876\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[29][6/30]\t Reward: -26.84212474018335\t States: [-0.18435219  1.0532982   0.10084938 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  877\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[29][7/30]\t Reward: -26.856706420481203\t States: [-0.18435219  1.0545806   0.10086697 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  878\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[29][8/30]\t Reward: -26.769400070011613\t States: [-0.18435219  1.0485562   0.10059634 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  879\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[29][9/30]\t Reward: -26.98472006112337\t States: [-0.18435219  1.0619811   0.10140705 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  880\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[29][10/30]\t Reward: -26.859725991785524\t States: [-0.18435219  1.0507609   0.10127913 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  881\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[29][11/30]\t Reward: -26.87084896355867\t States: [-0.18435219  1.0520376   0.10126269 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  882\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[29][12/30]\t Reward: -26.951797733604906\t States: [-0.18435219  1.0574254   0.1015334  62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  883\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[29][13/30]\t Reward: -27.0185468891263\t States: [-0.18435219  1.063097    0.10163373 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  884\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[29][14/30]\t Reward: -26.751264135092498\t States: [-0.1843522   1.0499498   0.10034322 62.15601   ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  885\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[29][15/30]\t Reward: -26.70187217980623\t States: [-0.18435219  1.0438356   0.10039312 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  886\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[29][16/30]\t Reward: -26.818892661631104\t States: [-0.18435219  1.0520159   0.10095125 62.017654  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  887\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[29][17/30]\t Reward: -26.964634338915346\t States: [-0.18435219  1.0592874   0.10147556 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  888\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[29][18/30]\t Reward: -26.96473712712526\t States: [-0.18435219  1.0640681   0.10142031 61.801815  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  889\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[29][19/30]\t Reward: -26.778375200033185\t States: [-0.18435216  1.0529346   0.10063661 61.835243  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  890\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[29][20/30]\t Reward: -26.814834175109862\t States: [-0.18435216  1.0542982   0.10074227 61.957825  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  891\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[29][21/30]\t Reward: -26.541308555901047\t States: [-0.18435219  1.0345806   0.09994255 61.99404   ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  892\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[29][22/30]\t Reward: -26.782531998604536\t States: [-0.1843522   1.0483581   0.10079306 62.178013  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  893\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[29][23/30]\t Reward: -26.80105834826827\t States: [-0.18435203  1.0584012   0.1014583  60.69373   ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  894\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[29][24/30]\t Reward: -27.206781742572783\t States: [-0.18435216  1.0768952   0.1023978  61.96206   ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  895\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[29][25/30]\t Reward: -26.902835198938845\t States: [-0.18435207  1.059312    0.10215831 60.92041   ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  896\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[29][26/30]\t Reward: -26.755948241055012\t States: [-0.18435195  1.0629188   0.10154261 59.706562  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  897\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[29][27/30]\t Reward: -26.67168968394399\t States: [-0.18435188  1.0621889   0.1013629  59.116676  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  898\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[29][28/30]\t Reward: -26.748179754763843\t States: [-0.18435211  1.0506549   0.10111536 61.282513  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  899\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[29][29/30]\t Reward: -25.099886871874332\t States: [-0.18435016  1.0584277   0.10140881 43.728855  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  900\n",
            "input shape, \n",
            "------------training--------------\n",
            "-----------------evaluating---------------\n",
            "input shape:  torch.Size([1, 3, 1024])\n",
            "[30][0/30]\t Reward: -21.181120450738817\t States: [-0.18435365  1.0704246   0.10473981  0.01049847]\n",
            "input shape:  torch.Size([1, 3, 1024])\n",
            "[30][1/30]\t Reward: -19.829888926744463\t States: [-0.18435675  1.00727     0.09742516  0.12829295]\n",
            "input shape:  torch.Size([1, 3, 1024])\n",
            "[30][2/30]\t Reward: -18.29675635436819\t States: [-1.8435241e-01  8.6943346e-01  9.6005768e-02  1.4456575e-05]\n",
            "input shape:  torch.Size([1, 3, 1024])\n",
            "[30][3/30]\t Reward: -23.48712142638862\t States: [-0.1843543   1.248623    0.10996839  0.02208344]\n",
            "input shape:  torch.Size([1, 3, 1024])\n",
            "[30][4/30]\t Reward: -19.965396983101964\t States: [-0.184349    1.0311666   0.09646384  0.0550354 ]\n",
            "input shape:  torch.Size([1, 3, 1024])\n",
            "[30][5/30]\t Reward: -20.3737503628619\t States: [-0.18435127  1.0512645   0.09858786  0.00476036]\n",
            "---------------------------------------\n",
            "Evaluation over 6 episodes: -20.522339\n",
            "---------------------------------------\n",
            "------------testing policy-----------\n",
            "input shape:  torch.Size([1, 3, 1024])\n",
            "[30][0/30]\t Reward: -20.049304572045806\t States: [-0.18435615  1.0422837   0.09615617  0.09007223]\n",
            "input shape:  torch.Size([1, 3, 1024])\n",
            "[30][1/30]\t Reward: -24.499055313952265\t States: [-0.1843546   1.3284515   0.11209794  0.02902492]\n",
            "input shape:  torch.Size([1, 3, 1024])\n",
            "[30][2/30]\t Reward: -20.18346290245652\t States: [-0.1843484   1.0145515   0.10028324  0.07780684]\n",
            "input shape:  torch.Size([1, 3, 1024])\n",
            "[30][3/30]\t Reward: -20.889199707508084\t States: [-0.18435328  1.0530602   0.10356244  0.00510735]\n",
            "input shape:  torch.Size([1, 3, 1024])\n",
            "[30][4/30]\t Reward: -19.15617739379406\t States: [-0.1843473   0.96869487  0.09452868  0.14517756]\n",
            "input shape:  torch.Size([1, 3, 1024])\n",
            "[30][5/30]\t Reward: -21.130096157193186\t States: [-0.1843496   1.0500269   0.10624327  0.0365696 ]\n",
            "input shape:  torch.Size([1, 3, 1024])\n",
            "[30][6/30]\t Reward: -20.624278478175402\t States: [-0.1843509   1.0168256   0.10453156  0.01023765]\n",
            "input shape:  torch.Size([1, 3, 1024])\n",
            "[30][7/30]\t Reward: -22.00612753084861\t States: [-0.18435106  1.1402221   0.10601294  0.00769254]\n",
            "input shape:  torch.Size([1, 3, 1024])\n",
            "[30][8/30]\t Reward: -22.12095776513219\t States: [-0.1843545   1.1216327   0.10900223  0.02564758]\n",
            "input shape:  torch.Size([1, 3, 1024])\n",
            "[30][9/30]\t Reward: -20.33661183681339\t States: [-0.18435425  1.0294716   0.10038047  0.02005397]\n",
            "input shape:  torch.Size([1, 3, 1024])\n",
            "[30][10/30]\t Reward: -22.672503945231437\t States: [-0.18435545  1.1854041   0.10810283  0.06336942]\n",
            "input shape:  torch.Size([1, 3, 1024])\n",
            "[30][11/30]\t Reward: -19.407118117213248\t States: [-0.18435353  0.9364346   0.10040109  0.00819457]\n",
            "---------------------------------------\n",
            "Evaluation over 12 episodes: -21.089574\n",
            "---------------------------------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[30][0/30]\t Reward: -25.841205899268388\t States: [-0.18435104  1.0569631   0.101113   51.584316  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  901\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[30][1/30]\t Reward: -25.1374336142838\t States: [-0.1843502   1.0587016   0.10120945 44.27629   ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  902\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[30][2/30]\t Reward: -25.039693429917094\t States: [-0.1843503   1.0466819   0.10081676 44.893555  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  903\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[30][3/30]\t Reward: -23.48462078154087\t States: [-0.1843484   1.0437118   0.10084532 29.611273  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  904\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[30][4/30]\t Reward: -24.53560556918383\t States: [-0.18434957  1.0530193   0.10132384 38.71185   ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  905\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[30][5/30]\t Reward: -22.76602770984173\t States: [-0.18434733  1.052289    0.10103351 21.379433  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  906\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[30][6/30]\t Reward: -21.91779574036598\t States: [-0.18434632  1.0418805   0.10048345 14.488027  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  907\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[30][7/30]\t Reward: -22.166837070435285\t States: [-0.18434624  1.0662469   0.10121422 13.811034  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  908\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[30][8/30]\t Reward: -22.402289012819526\t States: [-0.18434681  1.052262    0.10117708 17.60118   ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  909\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[30][9/30]\t Reward: -22.249864488542077\t States: [-0.184347    1.0343268   0.10024445 18.803083  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  910\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[30][10/30]\t Reward: -21.42142273321748\t States: [-0.18434478  1.0630952   0.10177463  6.111646  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  911\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[30][11/30]\t Reward: -21.349288864284755\t States: [-0.18434478  1.0587329   0.10144588  6.155284  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  912\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[30][12/30]\t Reward: -21.273123477846383\t States: [-0.18434514  1.0444843   0.1006436   7.6207695 ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  913\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[30][13/30]\t Reward: -21.50415247231722\t States: [-0.1843448   1.0724593   0.10187291  5.90425   ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  914\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[30][14/30]\t Reward: -20.73584094762802\t States: [-0.18434298  1.0530863   0.1013269   0.70444936]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  915\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[30][15/30]\t Reward: -21.545478668957948\t States: [-0.18434556  1.0503982   0.1010379   9.358624  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  916\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[30][16/30]\t Reward: -20.754719479084017\t States: [-0.18434298  1.0606335   0.10089418  0.57122356]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  917\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[30][17/30]\t Reward: -20.85946710884571\t States: [-0.18434304  1.0606236   0.10176566  0.7482098 ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  918\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[30][18/30]\t Reward: -20.992354731075466\t States: [-0.18434227  1.0776119   0.10212058  0.02334247]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  919\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[30][19/30]\t Reward: -20.63751033902168\t States: [-0.18434322  1.0467849   0.10089447  0.7837078 ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  920\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[30][20/30]\t Reward: -20.865538326501845\t States: [-0.18434322  1.0625972   0.10143571  0.94152737]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  921\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[30][21/30]\t Reward: -20.774985816255214\t States: [-0.18434237  1.0591229   0.10176671  0.05242641]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  922\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[30][22/30]\t Reward: -20.579116118723178\t States: [-1.8434153e-01  1.0493281e+00  1.0083952e-01  4.0014708e-04]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  923\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[30][23/30]\t Reward: -20.4803135868907\t States: [-0.18434343  1.0325917   0.10039488  1.1306492 ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  924\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[30][24/30]\t Reward: -20.097197686731814\t States: [-0.18434098  1.016047    0.09933737  0.01147348]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  925\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[30][25/30]\t Reward: -20.869421901404856\t States: [-0.1843395   1.0576984   0.10157114  1.3348055 ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  926\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[30][26/30]\t Reward: -20.656442691758276\t States: [-0.18434145  1.0557842   0.10094742  0.02014546]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  927\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[30][27/30]\t Reward: -20.73004086125642\t States: [-0.18434198  1.061508    0.10112552  0.00564502]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  928\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[30][28/30]\t Reward: -20.399736470282075\t States: [-0.18434021  1.0379293   0.0998507   0.33530173]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  929\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[30][29/30]\t Reward: -20.560222594588993\t States: [-0.18434064  1.0462177   0.1008932   0.06882444]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  930\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[31][0/30]\t Reward: -20.903302551060914\t States: [-0.18433996  1.0661227   0.10180607  0.5962595 ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  931\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[31][1/30]\t Reward: -20.636608602553604\t States: [-0.18434007  1.0486562   0.10103698  0.44504875]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  932\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[31][2/30]\t Reward: -20.912409528046847\t States: [-0.18434007  1.0681074   0.10166231  0.63261664]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  933\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[31][3/30]\t Reward: -20.643159199506044\t States: [-0.18434085  1.051604    0.10122038  0.03237042]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  934\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[31][4/30]\t Reward: -20.77410992488265\t States: [-0.18433939  1.049278    0.10128398  1.5108808 ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  935\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[31][5/30]\t Reward: -20.921948709636926\t States: [-0.18433894  1.0552537   0.10126648  2.4091978 ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  936\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[31][6/30]\t Reward: -20.574467443227768\t States: [-0.18434036  1.0456612   0.10089841  0.26170444]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  937\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[31][7/30]\t Reward: -22.24149195805192\t States: [-0.18433656  1.0662066   0.10185237 13.923456  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  938\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[31][8/30]\t Reward: -21.322046373933556\t States: [-0.18433796  1.0565565   0.10147199  6.0743933 ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  939\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[31][9/30]\t Reward: -20.72091898858547\t States: [-0.18434012  1.0561115   0.10125294  0.3266671 ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  940\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[31][10/30]\t Reward: -20.827978446632624\t States: [-0.18433894  1.0482577   0.10087376  2.5618188 ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  941\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[31][11/30]\t Reward: -20.973136955648663\t States: [-0.1843387   1.0511309   0.10117239  3.427459  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  942\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[31][12/30]\t Reward: -21.344164675325153\t States: [-0.18433748  1.0424678   0.10087669  8.299741  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  943\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[31][13/30]\t Reward: -21.355839914530513\t States: [-0.18433754  1.0466355   0.10089001  7.986404  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  944\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[31][14/30]\t Reward: -21.269423983991146\t States: [-0.18433735  1.0359409   0.10036436  8.717353  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  945\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[31][15/30]\t Reward: -21.525328434854742\t States: [-0.18433763  1.0614514   0.10148024  7.609469  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  946\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[31][16/30]\t Reward: -21.503853157907727\t States: [-0.18433727  1.0483247   0.10087337  9.314261  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  947\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[31][17/30]\t Reward: -23.05682274982333\t States: [-0.1843354   1.0655257   0.10127726 22.719967  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  948\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[31][18/30]\t Reward: -21.27797557622194\t States: [-0.1843386   1.0738946   0.10174336  3.6285045 ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  949\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[31][19/30]\t Reward: -21.635856356471777\t States: [-0.18433712  1.051442    0.10110015 10.09578   ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  950\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[31][20/30]\t Reward: -22.16181333765388\t States: [-0.18433641  1.053938    0.10138324 14.822658  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  951\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[31][21/30]\t Reward: -22.120460512787105\t States: [-0.18433656  1.0610402   0.10141548 13.666677  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  952\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[31][22/30]\t Reward: -23.111315184533595\t States: [-0.18433508  1.0442599   0.10060255 26.066175  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  953\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[31][23/30]\t Reward: -21.868201490342614\t States: [-0.18433651  1.0388153   0.10072266 14.0594    ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  954\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[31][24/30]\t Reward: -21.117453681528566\t States: [-0.184338    1.0461923   0.10049449  6.042385  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  955\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[31][25/30]\t Reward: -21.69410520195961\t States: [-0.1843375   1.0668906   0.10199086  8.242695  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  956\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[31][26/30]\t Reward: -21.40107792288065\t States: [-0.18433776  1.0570264   0.10116012  7.129583  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  957\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[31][27/30]\t Reward: -22.247440480142828\t States: [-0.1843362   1.0516753   0.10101118 16.27726   ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  958\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[31][28/30]\t Reward: -22.178578000962734\t States: [-0.18433627  1.0539662   0.10074133 15.629403  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  959\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[31][29/30]\t Reward: -24.23937320277095\t States: [-0.18433408  1.0460078   0.10067023 37.10429   ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  960\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[32][0/30]\t Reward: -22.788279232978823\t States: [-0.18433547  1.0447055   0.10085832 22.535492  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  961\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[32][1/30]\t Reward: -22.80071680635214\t States: [-0.1843352   1.0351392   0.09991658 24.55823   ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  962\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[32][2/30]\t Reward: -22.623600281327963\t States: [-0.18433581  1.0548394   0.1012371  19.496529  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  963\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[32][3/30]\t Reward: -25.148473933935165\t States: [-0.18433368  1.0668104   0.10209599 42.689278  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  964\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[32][4/30]\t Reward: -26.11473118752241\t States: [-0.18433282  1.0497713   0.10072887 55.42288   ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  965\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[32][5/30]\t Reward: -26.524182278066874\t States: [-0.18433274  1.0680004   0.10185264 56.570705  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  966\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[32][6/30]\t Reward: -26.12388718783855\t States: [-0.18433279  1.0429317   0.10060747 56.3198    ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  967\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[32][7/30]\t Reward: -26.31121560841799\t States: [-0.18433264  1.0396843   0.10041493 58.71036   ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  968\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[32][8/30]\t Reward: -26.903614965975287\t States: [-0.18433252  1.0691022   0.10153145 60.576054  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  969\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[32][9/30]\t Reward: -26.619215503633022\t States: [-0.18433246  1.0368631   0.10081333 61.674084  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  970\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[32][10/30]\t Reward: -26.741704669445753\t States: [-0.18433242  1.045635    0.10062689 62.20823   ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  971\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[32][11/30]\t Reward: -27.07179464966059\t States: [-0.1843324   1.0650558   0.10197032 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  972\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[32][12/30]\t Reward: -27.025206318199636\t States: [-0.1843324   1.0638801   0.10162202 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  973\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[32][13/30]\t Reward: -26.82872795134783\t States: [-0.1843324   1.0529059   0.10075465 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  974\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[32][14/30]\t Reward: -26.978762826025488\t States: [-0.1843324   1.0604231   0.10150328 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  975\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[32][15/30]\t Reward: -27.066268106997015\t States: [-0.1843324   1.0672116   0.10169948 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  976\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[32][16/30]\t Reward: -27.051236858665945\t States: [-0.1843324   1.0650002   0.10177031 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  977\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[32][17/30]\t Reward: -26.920820703804495\t States: [-0.1843324   1.0570649   0.10125968 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  978\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[32][18/30]\t Reward: -26.83330409795046\t States: [-0.1843324  1.049692   0.1011218 62.223606 ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  979\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[32][19/30]\t Reward: -26.80721261173487\t States: [-0.1843324   1.0509802   0.10073207 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  980\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[32][20/30]\t Reward: -27.011047234833242\t States: [-0.1843324  1.0651354  0.1013549 62.223606 ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  981\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[32][21/30]\t Reward: -27.06447981864214\t States: [-0.1843324   1.0688118   0.10152158 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  982\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[32][22/30]\t Reward: -26.704927166998388\t States: [-0.1843324   1.040936    0.10071363 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  983\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[32][23/30]\t Reward: -26.91741355329752\t States: [-0.1843324   1.0555283   0.10137927 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  984\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[32][24/30]\t Reward: -26.59479104548693\t States: [-0.1843324   1.0376503   0.09994084 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  985\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[32][25/30]\t Reward: -26.690270980894567\t States: [-0.1843324   1.0380867   0.10085201 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  986\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[32][26/30]\t Reward: -26.81648873358965\t States: [-0.1843324   1.050267    0.10089615 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  987\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[32][27/30]\t Reward: -26.939194133579733\t States: [-0.1843324   1.0574069   0.10140921 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  988\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[32][28/30]\t Reward: -26.838703086674215\t States: [-0.1843324   1.0508727   0.10105772 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  989\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[32][29/30]\t Reward: -26.934010764658453\t States: [-0.1843324  1.0552737  0.1015707 62.223606 ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  990\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[33][0/30]\t Reward: -26.99939661294222\t States: [-0.1843324  1.0611082  0.1016411 62.223606 ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  991\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[33][1/30]\t Reward: -26.846685191690923\t States: [-0.1843324   1.0530958   0.10091523 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  992\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[33][2/30]\t Reward: -26.85166292458773\t States: [-0.1843324   1.0509316   0.10118143 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  993\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[33][3/30]\t Reward: -26.874178877174856\t States: [-0.1843324   1.0528966   0.10121009 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  994\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[33][4/30]\t Reward: -27.026748886406423\t States: [-0.1843324   1.0611137   0.10191408 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  995\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[33][5/30]\t Reward: -26.850547870695593\t States: [-0.1843324   1.0540667   0.10085677 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  996\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[33][6/30]\t Reward: -26.94309823781252\t States: [-0.1843324   1.0564622   0.10154273 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  997\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[33][7/30]\t Reward: -26.83211111098528\t States: [-0.1843324   1.0523782   0.10084125 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  998\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[33][8/30]\t Reward: -26.714544823467733\t States: [-0.1843324   1.0452199   0.10038142 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  999\n",
            "input shape, \n",
            "------------training--------------\n",
            "input shape:  torch.Size([79, 3, 1024])\n",
            "[33][9/30]\t Reward: -26.918090215027334\t States: [-0.1843324   1.0568404   0.10125482 62.223606  ]\n",
            "epsiode_timesteps:  1\n",
            "total_timesteps:  1000\n",
            "Average Loss :None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fN4VnWagVxv_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}