{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyOS9RanKE9n/HWyutBgxnAe"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Reading the input data\n",
        "from google.colab import drive\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aTIjArdKjk7T",
        "outputId": "7782e943-4b97-40b9-b472-ff55a2e2a8c7"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Reading and using GFVs generated by AE"
      ],
      "metadata": {
        "id": "RS_kOE8hEUDy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the data into train and test sets\n",
        "import os\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "drive_root = '/content/drive/MyDrive/RLFinalProjectFiles'\n",
        "org_root = os.path.join(drive_root, 'shape_net_core_uniform_samples_2048')\n",
        "\n",
        "del_ratio = 50\n",
        "\n",
        "import numpy as np\n",
        "from random import random\n",
        "\n",
        "def read_gfv_data(file_path):\n",
        "    gfvs = np.load(file_path)\n",
        "    return gfvs\n",
        "\n",
        "# Example usage\n",
        "directory = drive_root + \"/gfv_vae3/50/\"\n",
        "def read_all_gfv_data(directory):\n",
        "    gfvs = []\n",
        "    for filename in os.listdir(directory):\n",
        "        if filename.endswith(\".npy\"):\n",
        "            file_path = os.path.join(directory, filename)\n",
        "            gfvs.extend(read_gfv_data(file_path))\n",
        "    return gfvs\n",
        "\n",
        "from sklearn.decomposition import KernelPCA\n",
        "\n",
        "gfvs = read_all_gfv_data(directory)\n",
        "print(len(gfvs))\n",
        "selected_gfvs = gfvs[:2500]\n",
        "gfvs_tensor = torch.tensor(np.array(selected_gfvs))\n",
        "\n",
        "# Step 4: Apply Kernel PCA\n",
        "# kpca = KernelPCA(n_components=256, kernel='rbf')\n",
        "# transformed_data = kpca.fit_transform(gfvs_tensor.numpy())\n",
        "\n",
        "# # Step 5: Get number of components\n",
        "# # num_components = kpca.n_components_\n",
        "\n",
        "# # Print shape of data\n",
        "# print(transformed_data.shape)\n",
        "print(gfvs[0].shape)\n",
        "\n",
        "# Reshape the tensor to [N, C, W, H] assuming the shape of each GFV is already [C, W, H]\n",
        "# If not, adjust the shape accordingly\n",
        "gfvs_tensor = torch.tensor(gfvs_tensor).unsqueeze(2)  # Add a channel dimension assuming it's missing\n",
        "# gfvs_tensor = gfvs_tensor.permute(0, 3, 1, 2)  # Permute dimensions to [N, C, W, H]\n",
        "print(gfvs_tensor.shape)\n",
        "\n",
        "if gfvs is not None:\n",
        "    print(\"GFV data shape:\", gfvs_tensor.shape)\n",
        "else:\n",
        "    print(\"Failed to read GFV data.\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D0PSoqVYjk5D",
        "outputId": "b7bb5c99-25bb-46a8-f7e5-724c630ff7d8"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2609\n",
            "(256,)\n",
            "torch.Size([2500, 256, 1])\n",
            "GFV data shape: torch.Size([2500, 256, 1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-9ab4b9b96f8e>:49: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  gfvs_tensor = torch.tensor(gfvs_tensor).unsqueeze(2)  # Add a channel dimension assuming it's missing\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Autoencoder for feature dimension reduction for encoder output"
      ],
      "metadata": {
        "id": "ZOz__W8eTJK-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### GAN architecture"
      ],
      "metadata": {
        "id": "p1_ptxsANdgG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "\n",
        "class SelfAttention(nn.Module):\n",
        "    \"\"\"Self Attention Layer.\"\"\"\n",
        "\n",
        "    def __init__(self, in_dim):\n",
        "        super(SelfAttention, self).__init__()\n",
        "\n",
        "        self.query_conv = nn.Conv2d(in_channels=in_dim, out_channels=in_dim//8, kernel_size=1)\n",
        "        self.key_conv = nn.Conv2d(in_channels=in_dim, out_channels=in_dim//8, kernel_size=1)\n",
        "        self.value_conv = nn.Conv2d(in_channels=in_dim, out_channels=in_dim, kernel_size=1)\n",
        "        self.gamma = nn.Parameter(torch.zeros(1))\n",
        "\n",
        "    def forward(self, x):\n",
        "        batch, channels, height, width = x.size()\n",
        "\n",
        "        proj_query = self.query_conv(x).view(batch, -1, height*width).permute(0, 2, 1)\n",
        "        proj_key = self.key_conv(x).view(batch, -1, height*width)\n",
        "\n",
        "        energy = torch.bmm(proj_query, proj_key)\n",
        "        attention = F.softmax(energy, dim=-1)\n",
        "\n",
        "        proj_value = self.value_conv(x).view(batch, -1, height*width)\n",
        "\n",
        "        out = torch.bmm(proj_value, attention.permute(0, 2, 1))\n",
        "        out = out.view(batch, channels, height, width)\n",
        "\n",
        "        out = self.gamma * out + x\n",
        "        return out\n",
        "\n",
        "class Generator(nn.Module):\n",
        "    \"\"\"Generator.\"\"\"\n",
        "\n",
        "    def __init__(self, z_dim=1, gfvs_dim=256, conv_dim=64):\n",
        "        super(Generator, self).__init__()\n",
        "        self.gfvs_dim = gfvs_dim\n",
        "\n",
        "        # Calculate the initial image size based on the GFVs shape\n",
        "        self.initial_image_size = int(np.sqrt(gfvs_dim / conv_dim / 4))\n",
        "\n",
        "        # Adjust the input dimension to match the latent vector size\n",
        "        self.fc = nn.Linear(z_dim, conv_dim * 8 * self.initial_image_size * self.initial_image_size)\n",
        "\n",
        "        # Define the convolutional layers\n",
        "        self.conv1 = nn.ConvTranspose2d(conv_dim * 8, conv_dim * 4, 4, 2, 1)\n",
        "        self.sa1 = SelfAttention(conv_dim * 4)\n",
        "        self.conv2 = nn.ConvTranspose2d(conv_dim * 4, conv_dim * 2, 4, 2, 1)\n",
        "        self.sa2 = SelfAttention(conv_dim * 2)\n",
        "        self.conv3 = nn.ConvTranspose2d(conv_dim * 2, conv_dim, 4, 2, 1)\n",
        "        self.sa3 = SelfAttention(conv_dim)\n",
        "        self.conv4 = nn.ConvTranspose2d(conv_dim , 1, 4, 2, 1)  # Output should match GFVs size\n",
        "        self.fc_output = nn.Linear(conv_dim * self.initial_image_size * self.initial_image_size, gfvs_dim)\n",
        "\n",
        "    def forward(self, z):\n",
        "        out = self.fc(z)\n",
        "        out = out.view(-1, 64 * 8, self.initial_image_size, self.initial_image_size)\n",
        "        out = F.relu(self.conv1(out))\n",
        "        out = self.sa1(out)\n",
        "        out = F.relu(self.conv2(out))\n",
        "        out = self.sa2(out)\n",
        "        out = F.relu(self.conv3(out))\n",
        "        out = self.sa3(out)\n",
        "        out = torch.tanh(self.conv4(out))  # Apply tanh activation for image generation\n",
        "        # out = out.squeeze()  # Flatten the output\n",
        "        out = out.permute(0, 2, 3, 1)\n",
        "        out = out.view(-1, 64 * self.initial_image_size * self.initial_image_size) # Reshape to match GFVs dimension\n",
        "        return out\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "class Discriminator(nn.Module):\n",
        "    \"\"\"Discriminator.\"\"\"\n",
        "\n",
        "    def __init__(self, gfvs_dim=256, conv_dim=64):\n",
        "        super(Discriminator, self).__init__()\n",
        "        self.gfvs_dim = gfvs_dim\n",
        "\n",
        "        # Calculate the final image size based on the GFVs shape\n",
        "        self.final_image_size = int(np.sqrt(gfvs_dim/ conv_dim / 4))\n",
        "\n",
        "        # Adjust the input dimension to match the GFVs size\n",
        "        self.conv1 = nn.Conv2d(1, conv_dim, 1)\n",
        "        self.conv2 = nn.Conv2d(conv_dim, conv_dim * 2, 3, 2, 1)\n",
        "        self.sa1 = SelfAttention(conv_dim * 2)\n",
        "        self.conv3 = nn.Conv2d(conv_dim * 2, conv_dim * 4, 3, 2, 1)\n",
        "        self.sa2 = SelfAttention(conv_dim * 4)\n",
        "        self.conv4 = nn.Conv2d(conv_dim * 4, 1, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = F.leaky_relu(self.conv1(x), 0.2)\n",
        "        out = F.leaky_relu(self.conv2(out), 0.2)\n",
        "        out = self.sa1(out)\n",
        "        out = F.leaky_relu(self.conv3(out), 0.2)\n",
        "        out = self.sa2(out)\n",
        "        out = self.conv4(out)\n",
        "        return out.squeeze()  # Return a 1D output\n"
      ],
      "metadata": {
        "id": "BPJO-8kSjeB0"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chamfer Loss"
      ],
      "metadata": {
        "id": "Mo7d7B-J-6Vh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install faiss-cpu"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FnGk5l8b_oHB",
        "outputId": "52ac3b48-d33e-4124-e03a-eb9f0450540a"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting faiss-cpu\n",
            "  Downloading faiss_cpu-1.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (27.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m27.0/27.0 MB\u001b[0m \u001b[31m30.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from faiss-cpu) (1.25.2)\n",
            "Installing collected packages: faiss-cpu\n",
            "Successfully installed faiss-cpu-1.8.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import faiss\n",
        "import torch.nn as nn\n",
        "\n",
        "\n",
        "def robust_norm(var):\n",
        "    '''\n",
        "    :param var: Variable of BxCxHxW\n",
        "    :return: p-norm of BxCxW\n",
        "    '''\n",
        "    result = ((var**2).sum(dim=2) + 1e-8).sqrt()\n",
        "    # result = (var ** 2).sum(dim=2)\n",
        "\n",
        "    # try to make the points less dense, caused by the backward loss\n",
        "    # result = result.clamp(min=7e-3, max=None)\n",
        "    return result\n",
        "\n",
        "class ChamferLoss(nn.Module):\n",
        "    def __init__(self, opt):\n",
        "        super(ChamferLoss, self).__init__()\n",
        "        self.dimension = 3\n",
        "        self.k = 1\n",
        "\n",
        "        # we need only a StandardGpuResources per GPU\n",
        "        # self.res = faiss.StandardGpuResources()\n",
        "        # self.res.setTempMemoryFraction(0.1)\n",
        "\n",
        "        # place holder\n",
        "        self.forward_loss = torch.FloatTensor([0])\n",
        "        self.backward_loss = torch.FloatTensor([0])\n",
        "\n",
        "    def build_nn_index(self, database):\n",
        "        '''\n",
        "        :param database: numpy array of Nx3\n",
        "        :return: Faiss index, in CPU\n",
        "        '''\n",
        "        database = np.ascontiguousarray(database)\n",
        "        index = faiss.IndexFlatL2(self.dimension)\n",
        "        index.add(database)\n",
        "        return index\n",
        "\n",
        "    def search_nn(self, index, query, k):\n",
        "        '''\n",
        "        :param index: Faiss index\n",
        "        :param query: numpy array of Nx3\n",
        "        :return: D: Variable of Nxk, type FloatTensor, in CPU\n",
        "                 I: Variable of Nxk, type LongTensor, in CPU\n",
        "        '''\n",
        "        D, I = index.search(query, k)\n",
        "\n",
        "        D_var = torch.from_numpy(np.ascontiguousarray(D))\n",
        "        I_var = torch.from_numpy(np.ascontiguousarray(I).astype(np.int64))\n",
        "\n",
        "        return D_var, I_var\n",
        "\n",
        "    def forward(self, predict_pc, gt_pc):\n",
        "        '''\n",
        "        :param predict_pc: Bx3xM Variable in CPU\n",
        "        :param gt_pc: Bx3xN Variable in CPU\n",
        "        :return:\n",
        "        '''\n",
        "        # for VAE\n",
        "        # predict_pc = predict_pc[0]\n",
        "        predict_pc_size = predict_pc.size()\n",
        "        gt_pc_size = gt_pc.size()\n",
        "\n",
        "        # print(predict_pc.shape)\n",
        "\n",
        "        predict_pc_np = np.ascontiguousarray(torch.transpose(predict_pc.data.clone(), 1, 2).numpy())  # BxMx3\n",
        "        gt_pc_np = np.ascontiguousarray(torch.transpose(gt_pc.data.clone(), 1, 2).numpy())  # BxNx3\n",
        "\n",
        "        # selected_gt: Bxkx3xM\n",
        "        selected_gt_by_predict = torch.FloatTensor(predict_pc_size[0], self.k, predict_pc_size[1], predict_pc_size[2])\n",
        "        # selected_predict: Bxkx3xN\n",
        "        selected_predict_by_gt = torch.FloatTensor(gt_pc_size[0], self.k, gt_pc_size[1], gt_pc_size[2])\n",
        "\n",
        "        # process each batch independently.\n",
        "        for i in range(predict_pc_np.shape[0]):\n",
        "            index_predict = self.build_nn_index(predict_pc_np[i])\n",
        "            index_gt = self.build_nn_index(gt_pc_np[i])\n",
        "\n",
        "            # database is gt_pc, predict_pc -> gt_pc -----------------------------------------------------------\n",
        "            _, I_var = self.search_nn(index_gt, predict_pc_np[i], self.k)\n",
        "\n",
        "            # process nearest k neighbors\n",
        "            for k in range(self.k):\n",
        "                selected_gt_by_predict[i,k,...] = gt_pc[i].index_select(1, I_var[:,k])\n",
        "\n",
        "            # database is predict_pc, gt_pc -> predict_pc -------------------------------------------------------\n",
        "            _, I_var = self.search_nn(index_predict, gt_pc_np[i], self.k)\n",
        "\n",
        "            # process nearest k neighbors\n",
        "            for k in range(self.k):\n",
        "                selected_predict_by_gt[i,k,...] = predict_pc[i].index_select(1, I_var[:,k])\n",
        "\n",
        "        # compute loss ===================================================\n",
        "        # selected_gt(Bxkx3xM) vs predict_pc(Bx3xM)\n",
        "        forward_loss_element = robust_norm(selected_gt_by_predict-predict_pc.unsqueeze(1).expand_as(selected_gt_by_predict))\n",
        "        self.forward_loss = forward_loss_element.mean()\n",
        "        self.forward_loss_array = forward_loss_element.mean(dim=1).mean(dim=1)\n",
        "\n",
        "        # selected_predict(Bxkx3xN) vs gt_pc(Bx3xN)\n",
        "        backward_loss_element = robust_norm(selected_predict_by_gt - gt_pc.unsqueeze(1).expand_as(selected_predict_by_gt))  # BxkxN\n",
        "        self.backward_loss = backward_loss_element.mean()\n",
        "        self.backward_loss_array = backward_loss_element.mean(dim=1).mean(dim=1)\n",
        "\n",
        "        # self.loss_array = self.forward_loss_array + self.backward_loss_array\n",
        "        return self.forward_loss + self.backward_loss\n",
        "\n",
        "    def __call__(self, predict_pc, gt_pc):\n",
        "        # start_time = time.time()\n",
        "        loss = self.forward(predict_pc, gt_pc)\n",
        "        # print(time.time()-start_time)\n",
        "        return loss\n"
      ],
      "metadata": {
        "id": "QbzqFL9b-5rG"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Training GAN"
      ],
      "metadata": {
        "id": "rCs50Fli6PUl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.autograd as autograd\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from tqdm import tqdm\n",
        "from torch.autograd import Variable\n",
        "\n",
        "# Define device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Hyperparameters\n",
        "z_dim = 1\n",
        "pc_dim = 256\n",
        "batch_size = 50\n",
        "lr = 0.01\n",
        "num_epochs = 10\n",
        "lambda_gp = 10  # Gradient penalty coefficient\n",
        "\n",
        "# Initialize generator and discriminator\n",
        "generator = Generator(z_dim=z_dim, gfvs_dim=pc_dim, conv_dim=64)\n",
        "discriminator = Discriminator(gfvs_dim=pc_dim)\n",
        "\n",
        "chamfer_criterion = ChamferLoss({})\n",
        "# Optimizers\n",
        "optimizer_G = optim.Adam(generator.parameters(), lr=lr, betas=(0.5, 0.9))\n",
        "optimizer_D = optim.Adam(discriminator.parameters(), lr=lr, betas=(0.5, 0.9))\n",
        "\n",
        "# Dummy GFV data (replace with your actual GFV data)\n",
        "# num_samples = 1000\n",
        "gfvs_real_tensor = torch.tensor(selected_gfvs)\n",
        "gfvs_real = gfvs_real_tensor\n",
        "\n",
        "# Data loader\n",
        "dataset = TensorDataset(gfvs_real)\n",
        "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "# Gradient penalty calculation\n",
        "def compute_gradient_penalty(discriminator, real_samples, fake_samples):\n",
        "    alpha = torch.rand(batch_size, 1, 1, 1, device=device)\n",
        "\n",
        "    # Ensure the fake_samples have the same shape as real_samples\n",
        "    real_samples = real_samples.unsqueeze(0)\n",
        "    fake_samples = fake_samples.view(1, real_samples.size(1), real_samples.size(2))\n",
        "    interpolated = alpha * real_samples + (1 - alpha) * fake_samples\n",
        "    interpolated.requires_grad_(True)\n",
        "    prob_interpolated = discriminator(interpolated)\n",
        "    gradients = autograd.grad(outputs=prob_interpolated, inputs=interpolated,\n",
        "                              grad_outputs=torch.ones(prob_interpolated.size(), device=device),\n",
        "                              create_graph=True, retain_graph=True)[0]\n",
        "    gradients_norm = torch.sqrt(torch.sum(gradients ** 2, dim=(1, 2, 3)))\n",
        "    gradient_penalty = ((gradients_norm - 1) ** 2).mean()\n",
        "    return gradient_penalty\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(num_epochs):\n",
        "    for gfvs_batch in tqdm(dataloader):\n",
        "        # Move batch to device\n",
        "        gfvs_real_batch = gfvs_batch[0]\n",
        "        gfvs_real_batch_tensor = torch.stack(gfvs_batch)\n",
        "        # print(\"gfvs_batch \",gfvs_real_batch_tensor.shape)\n",
        "        gfvs_real_batch_tensor = gfvs_real_batch_tensor.view(batch_size,256,1)\n",
        "\n",
        "\n",
        "        # Train Discriminator\n",
        "        optimizer_D.zero_grad()\n",
        "        gfvs_real_batch_tensor = gfvs_real_batch_tensor.unsqueeze(1)\n",
        "        # Real batch\n",
        "        real_output = discriminator(gfvs_real_batch_tensor)\n",
        "        d_loss_real = -real_output.mean()\n",
        "\n",
        "        # Fake batch\n",
        "        fixed_z = torch.rand(batch_size, z_dim)  # Generate random values between 0 and 1\n",
        "        fake_gfvs = generator(fixed_z)\n",
        "        fake_gfvs = fake_gfvs.unsqueeze(0).unsqueeze(1)\n",
        "        fake_output = discriminator(fake_gfvs.detach())\n",
        "        d_loss_fake = fake_output.mean()\n",
        "\n",
        "        # Gradient penalty\n",
        "        gradient_penalty = compute_gradient_penalty(discriminator, gfvs_real_batch, fake_gfvs)\n",
        "\n",
        "        # Total loss\n",
        "        d_loss = d_loss_fake + d_loss_real + lambda_gp * gradient_penalty\n",
        "        d_loss.backward()\n",
        "        optimizer_D.step()\n",
        "\n",
        "        # Train Generator\n",
        "        optimizer_G.zero_grad()\n",
        "        z = torch.randn(gfvs_real_batch.size(0), z_dim, device=device)\n",
        "        fake_gfvs = generator(z)\n",
        "        fake_gfvs = fake_gfvs.view(batch_size, 1, 16, 16)\n",
        "        # print(\"fake_gfvs shape \",fake_gfvs.shape)\n",
        "        fake_output = discriminator(fake_gfvs)\n",
        "        g_loss_chamfer = chamfer_criterion(fake_gfvs, gfvs_real_batch.transpose(1, 2))\n",
        "        g_loss_gfv = torch.norm(fake_gfvs - gfvs_real_batch, p=2)\n",
        "        g_loss = g_loss_chamfer + g_loss_gfv\n",
        "        g_loss.backward()\n",
        "        optimizer_G.step()\n",
        "\n",
        "    # Print losses\n",
        "    print(f\"Epoch [{epoch + 1}/{num_epochs}], Discriminator Loss: {d_loss.item()}, Generator Loss: {g_loss.item()}\")\n",
        "\n",
        "# Save model\n",
        "torch.save(generator.state_dict(), drive_root + \"/models/generator2.pth\")\n",
        "torch.save(discriminator.state_dict(), drive_root +\"/models/discriminator2.pth\")\n"
      ],
      "metadata": {
        "id": "wV-VeYKH6Oqm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0lfQ4s-qAQGn"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}